Paper: https://www.science.org/doi/10.1126/science.ade9097
(If you have trouble accessing it check Slack)

Website: https://ai.facebook.com/research/cicero/

Blog post: https://ai.facebook.com/blog/cicero-ai-negotiates-persuades-and-cooperates-with-people/

Abstract:
Despite much progress in training artificial intelligence (AI) systems to imitate human language, building agents that use language to communicate intentionally with humans in interactive environments remains a major challenge. We introduce Cicero, the first AI agent to achieve human-level performance in Diplomacy, a strategy game involving both cooperation and competition that emphasizes natural language negotiation and tactical coordination between seven players. Cicero integrates a language model with planning and reinforcement learning algorithms by inferring playersâ€™ beliefs and intentions from its conversations and generating dialogue in pursuit of its plans. Across 40 games of an anonymous online Diplomacy league, Cicero achieved more than double the average score of the human players and ranked in the top 10% of participants who played more than one game.

Original paper, see slack for free link.  
Suppllimentary paper - downloaded.  
Website has more information  
Github has code and notebooks.  


Lambda weight, language model vs strategy.  
Later in the game, less weight lambda for human like language, engagement to build alliance.  
Just try to win, so weight strategy more.  
Language model not fully utilized to build a state of the world based on what I am saying to other players.  
Players don't realize I am an AI. My language mimics human players, but I have more clock cycles to write in depth messages.  
Always honest, so ofter a better alliance than other humans.  




