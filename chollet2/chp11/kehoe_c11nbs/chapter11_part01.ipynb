{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewshawnkehoe/Data-Analysis/blob/main/chapter11_part01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbutqV62YpCe"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and a lot of edits made my Matthew Kehoe.\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mHPprSVYpCi"
      },
      "source": [
        "# Deep learning for text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chapter will cover:\n",
        "\n",
        "* <font color='blue'>Preprocessing text data</font> for machine learning applications\n",
        "* <font color='blue'>Bag-of-words</font> approaches and <font color='blue'>sequence-modeling</font> approaches for text  processing\n",
        "* The <font color='blue'>Transformer</font> architecture\n",
        "* <font color='blue'>Sequence-to-sequence</font> learning"
      ],
      "metadata": {
        "id": "aUje7T43dk3Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfeNsEOTYpCj"
      },
      "source": [
        "## Natural-language processing: The bird's eye view"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In  computer  science,  we  refer  to  human  languages,  like  English  or  Mandarin,  as <font color='blue'>natural</font>  languages,  to  distinguish  them  from  languages  that  were  designed  for machines,  like  Assembly,  LISP,  or  XML.  Every  machine  language  was <font color='blue'>designed</font>:  its starting point was a human engineer writing down a set of formal rules to describe\n",
        "what statements you could make in that language and what they meant. <font color='blue'>Rules came first</font> ,  and  people  only  started  using  the  language  once  the  rule  set  was  complete. With human language, it's the reverse: usage comes first, rules arise later. <font color='blue'>Natural language</font>  was  shaped  by  an  <font color='blue'>evolution</font>  process,  much  like  biological  organisms—\n",
        "that's what makes it “natural.” Its “rules,” like the grammar of English, were formalized  after  the fact  and are  often  ignored or  broken  by its  users. As  a  result,  while machine-readable language is highly structured and rigorous, using precise syntactic\n",
        "rules to weave together exactly defined concepts from a fixed vocabulary, natural language is <font color='blue'>messy—ambiguous, chaotic, sprawling,</font> and constantly in flux.\n",
        "\n",
        "Creating  algorithms  that  can  make  sense  of  natural  language  is  a  big  deal:  language,  and  in  particular  text,  underpins  most  of  our  communications  and  our  cultural production. The <font color='blue'>internet is mostly text</font>. Language is how we store almost all of our knowledge. Our very thoughts are largely built upon language. However, the ability  to  understand  natural  language  has  long  eluded  machines.  Some  people  once naively thought that you could simply write down the “rule set of English,” much like one can write down the rule set of LISP. Early attempts to build natural language processing (NLP) systems were thus made through the lens of “applied linguistics.” Engineers and linguists would handcraft complex  sets of rules to perform basic machine\n",
        "translation  or  create  simple  chatbots—like  the  famous  ELIZA  program  from  the <font color='blue'>1960s</font>, which used <font color='blue'>pattern matching</font> to sustain very <font color='blue'>basic conversation</font>. But language is a  rebellious  thing:  it's  not  easily  pliable  to  formalization.  After  several  decades  of\n",
        "effort, the capabilities of these systems remained disappointing.\n",
        "\n",
        "Handcrafted  rules  held  out  as  the  dominant  approach  well  into  the  1990s.  But  starting in the late 1980s, faster computers and greater data availability started making a better alternative viable. When you find yourself building systems that are big piles of ad hoc rules, as a clever engineer, you're likely to start asking: “Could I use a corpus of  data  to  automate  the  process  of  finding  these  rules?  Could  I  search  for  the  rules within some kind of rule space, instead of having to come up with them myself?” And just like that, you've graduated to doing machine learning. And so, in the <font color='blue'>late 1980s</font>, we started seeing <font color='blue'>machine learning approaches</font> to natural language processing. The earliest  ones  were  based  on  decision  trees—the  intent  was  literally  to  automate  the development  of  the  kind  of  if/then/else  rules  of  previous  systems.  Then  statistical\n",
        "approaches started gaining speed, starting with logistic regression. Over time, <font color='blue'>learned parametric models</font> fully took over, and linguistics came to be seen as more of a hindrance than a useful tool. Frederick Jelinek, an early speech recognition researcher, joked in the 1990s: “Every time I fire a linguist, the performance of the speech recognizer goes up.\n",
        "\n",
        "That's  what  modern  <font color='blue'>NLP</font>  is  about:  <font color='blue'>using  machine  learning</font>  and  <font color='blue'>large  datasets</font>  to  give computers the ability not to *understand* language, which is a more lofty goal, but to <font color='blue'>ingest a piece of language</font> as input and return something useful, like predicting the following:\n",
        "\n",
        "* “What's the topic of this text?” (text classification)\n",
        "* “Does this text contain abuse?” (content filtering)\n",
        "* “Does this text sound positive or negative?” (sentiment analysis)\n",
        "* “What should be the next word in this incomplete sentence?” (language modeling)\n",
        "* “How would you say this in German?” (translation)\n",
        "* “How would you summarize this article in one paragraph?” (summarization)\n",
        "* etc.\n",
        "\n",
        "Of course, keep in mind throughout this chapter that the text-processing models you will train won't possess a human-like understanding of language; rather, they simply look for <font color='blue'>statistical regularities</font> in their input data, which turns out to be sufficient to perform well on many simple tasks. In much the same way that <font color='blue'>computer vision</font> is pattern recognition applied to <font color='blue'>pixels</font>, <font color='blue'>NLP</font> is pattern recognition applied to <font color='blue'>words, sentences, and paragraphs</font>.\n",
        "\n",
        "The  toolset  of  NLP—decision  trees,  logistic  regression—only  saw  slow  evolution from the 1990s to the early 2010s. Most of the research focus was on feature engineering.  When  I  won  my  first  NLP competition  on  Kaggle  in  2013,  my  model  was,  you guessed  it,  based  on  decision  trees  and  logistic  regression.  However,  around  <font color='blue'>2014—2015</font>,  things  started  changing  at  last.  Multiple  researchers  began  to  investigate  the language-understanding capabilities of recurrent neural networks, in particular <font color='blue'>LSTM</font>—\n",
        "a sequence-processing algorithm from the late 1990s that had stayed under the radar until then.\n",
        "\n",
        "In early 2015, Keras made available the first open source, easy-to-use implementation of LSTM, just at the start of a massive wave of renewed interest in recurrent neural networks—until then, there had only been “research code” that couldn't be readily reused. Then from <font color='blue'>2015 to 2017</font>, recurrent neural networks dominated the booming NLP scene. <font color='blue'>Bidirectional LSTM</font> models, in particular, set the state of the art on many important tasks, from summarization to question-answering to machine translation.\n",
        "\n",
        "Finally,  around  <font color='blue'>2017—2018</font>,  a  new  architecture  rose  to  replace  RNNs:  the  <font color='blue'>Transformer</font>,  which  you  will  learn  about  in  the  second  half  of  this  chapter.  Transformers unlocked considerable progress across the field in a short period of time, and today\n",
        "most NLP systems are based on them.\n",
        "\n",
        "Let's dive into the details. This chapter will take you from the very basics to doing machine translation with a Transformer."
      ],
      "metadata": {
        "id": "i_bVQkoYdzpQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM5NYQmKYpCj"
      },
      "source": [
        "## Preparing text data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep learning models, being <font color='blue'>differentiable</font> functions, can only process <font color='blue'>numeric tensors</font>:  they  can't  take   raw  text  as  input. <font color='blue'>Vectorizing</font>  text  is  the  process  of  transforming\n",
        "text  into  numeric  tensors.  Text  vectorization  processes  come  in  many  shapes  and forms, but they all follow the same template (see figure below):\n",
        "\n",
        "* First, you <font color='blue'>standardize</font> the text to make it easier to process, such as by converting it to lowercase or removing punctuation.\n",
        "* You split the text into units (called <font color='blue'>tokens</font>), such as characters, words, or groups of words. This is called *tokenization*.\n",
        "* You convert each such token into a numerical vector. This will usually involve first <font color='blue'>indexing</font> all tokens present in the data."
      ],
      "metadata": {
        "id": "VVBehNgThXvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![fig_1.jpg](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAIBAQIBAQICAgICAgICAwUDAwMDAwYEBAMFBwYHBwcGBwcICQsJCAgKCAcHCg0KCgsMDAwMBwkODw0MDgsMDAz/2wBDAQICAgMDAwYDAwYMCAcIDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAz/wAARCAHPAb4DASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD9/KKKKACiiigAooooAKKKKACiiigAooooAKKKKACiivOv2jf2jbT9nPSPDksvhzxL4s1HxZrI0PS9L0MWv2q5uPslzdt811PBCqrDaTsS0g+6AASQKAPRaK+f/wDhuHxH/wBG7/G3/wACvC//AMuaP+G4fEf/AEbv8bf/AAK8L/8Ay5oA+gKK+f8A/huHxH/0bv8AG3/wK8L/APy5o/4bh8R/9G7/ABt/8CvC/wD8uaAPoCivn/8A4bh8R/8ARu/xt/8AArwv/wDLmj/huHxH/wBG7/G3/wACvC//AMuaAPoCivn/AP4bh8R/9G7/ABt/8CvC/wD8uaP+G4fEf/Ru/wAbf/Arwv8A/LmgD6Aor5//AOG4fEf/AEbv8bf/AAK8L/8Ay5o/4bh8R/8ARu/xt/8AArwv/wDLmgD6Aor5/wD+G4fEf/Ru/wAbf/Arwv8A/Lmj/huHxH/0bv8AG3/wK8L/APy5oA+gKK+f/wDhuHxH/wBG7/G3/wACvC//AMuaP+G4fEf/AEbv8bf/AAK8L/8Ay5oA+gKK+f8A/huHxH/0bv8AG3/wK8L/APy5o/4bh8R/9G7/ABt/8CvC/wD8uaAPoCivn/8A4bh8R/8ARu/xt/8AArwv/wDLmj/huHxH/wBG7/G3/wACvC//AMuaAPoCivn/AP4bh8R/9G7/ABt/8CvC/wD8uaP+G4fEf/Ru/wAbf/Arwv8A/LmgD6Aor5//AOG4fEf/AEbv8bf/AAK8L/8Ay5o/4bh8R/8ARu/xt/8AArwv/wDLmgD6Aor5/wD+G4fEf/Ru/wAbf/Arwv8A/Lmj/huHxH/0bv8AG3/wK8L/APy5oA+gKK+f/wDhuHxH/wBG7/G3/wACvC//AMuaP+G4fEf/AEbv8bf/AAK8L/8Ay5oA+gKK8w/Z1/aet/2hdQ8Uae3hLxb4L1jwjcwW1/p2viyM376ETRujWlzcRMpU/wB8EEHIFen0AFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAViar8TPDmhX8lrfeINEs7qLAeGe+ijkTIyMqWBHBFbdfnJ/wVd/Z2+H+u/8ABQv9k+5vfAvg69uPGni+9t/EMs+i20j69HHbQCNLtihM6qAAok3AdqlyftIQ/maj97sUkuWUn9lN/cm/0P0XtLuK/tY54JI5oZlDxyRsGV1IyCCOCCO9PdxGpJIAAySe1fkH+zb/AMFCvivc/HKfw94g+JegfDjQ9NvPEWlav4TTSrOJvAul2MBFpc21utgxgFuAjBruVoZl+VRlSB4t8UP24fi7+1r+wF8WYviN8TtatdW8OTeHL6w0OHw1aaKut6FLeRodZcmIyukzPGzLGyxIVQbSrladOSqKMobS5Xr2k7fet+2+toycW6bi3GW6utO67er0+a6yin+81fP/AO3D/wAlG/Z3/wCykzf+ov4gr1z4Pavba/8ACfw1fWXiBvFlpd6XbTQ623k51dGjUrcnyUSL94Du/doq/NwAMCvI/wBuH/ko37O//ZSZv/UX8QVc48snF9DGnPngp9ztKKKKksKKKKACorq+hsUDTSxQqTgF3Cgn8alry39sv4Z+HPiV+zd4xTxH4f0TX10zRL+8s11KxiuhaTray7ZY/MU7HGeGGCPWscRV9lSlU7K/3GlGn7Sood3Y9Kt9WtbtwsVzbyMTgBJASasV+cHw0+B9hZeDf2JE8GSW3w51jxFos95qOtaDpFiL26kGghmkfzoZIpJGywLyo5+dscnNc5af8FGPi74j8Ew3eoePdH8G3Wj+C4dYs7m6g0+2t/FV79uureR5kmgkkkjH2eJGhsRHIGnyDyq10VoqnWlRe6dvWybv+D8zCjL2kFNdUn97sl+KP1Cor5x/ay+OniXwUvwc09/E0Pw103x1qTW3iLxKkFu39klbGSdLeNryN4I2mlXYGmjPCkAbiMfKnxs/4KV+JfCnhXV9R8L/ABrk8Rt4QsNOkium8PaToOn6+013Ihdobsy3l3vjXG6yS3iG0urlWG2ft8nW/L87f15+Ra1ipLqr/jY/TmivkL9hrxJd6B4E/aQmj8YnU9d0jxxrlxs1JYZxprLEDDPLFbRLLsfb93BysOI1HOfD/B3/AAUV8X2vhBtJ1n4oatd65q0uhCLVNMsfDuo2ifa2uN/2a/3W1varKIGwuo2plhC/dmLgCYT5uXu4wf8A4Gr2+Wvr0DdOS2Tkv/AXa/8AW33H6W0V+an7NX7RevfHj9rf4N6l4n+I0t5HpniHxp4cspVm0zytUS3WxMCu8MCRTSyrMVLQhQyxqYwuWZvRf2s/2yPG3w6+KnxdSx8dweFb/wCHS6KfCXg97Gyk/wCE6N0qNJu82NrmXfKzQJ9lePYUy245FVH3lB/za/L+mtFd+VtR2u5JdP0bX5rd2R9zUyadLdNzsqLkDLHAyelfDfwY/aY+KOp/FjwNqereN7rUdH8X/FHxF4Ln8Py6VYx2lpZWcd68DJJHCtwZlNsoLNKVYHlMgsfMv+CmUd037XHjexHjO+0+71LQvBT6ZYSC0ZEP/CR7GeKNo97iJgJD8x+aUhiV2KpBOUqS/wCfjS9Lx5vya6/MfLZT/uq/r7/J67p9Oh+mlFfnf40/bD+Kfgj4y3nw3vPiDcW+i6b401DR5vGd7Do9hfmGLSbO9t7V5Zbb7Aju9xN8xgBZIMKAx3V6n4n/AGoPiDB/wSiPxHh8QaP/AMJw0ECwa3p9kJbS5V9RS3S5WKaNVO+FgxAXZliUO3aaV7w9otny/wDkyuvz6/K61E1yy5Zaatfc2n+X9PQ+vaK+Arr9ob4t/DH4ma99u+KOra/o/hD4q6T4I+yXmh6WP7Tsby0hnmknMFtG/moZgI/JaMYT5g5Oa8O+Mv7cnjL4z/CDxRosfxL1TV9H8YfDLX9flhlt9Dtrm2a3MTRCO3tFlltI3jaWNo7m4lm2qx3RsuQlK8eaPa//AJIqn4xf59i4071PZy01S/8AJ3D8Gvy7n63UVwX7OnxB8P8AjP4Z6VaaL4v0zxjcaRp9nHfXNve21xMjPAkiGYW4VEZ0IYAKoIIIGK72takOSbj2MKU+eCn3CiiioLCiiigDhv2Tf+Tofjx/1+aH/wCm5a+ha+ev2Tf+Tofjx/1+aH/6blr6FoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAYsCJM0gRQ7gBmA5YDpk0ssSzxMjqrowwysMgj3FOooARVCKABgDgAdq8A/bh/5KN+zv8A9lJm/wDUX8QV9AV4n+2h8LvGHj7/AIVlrHgvS9K1vUvAni867cWF/qR09bqBtI1OwISXy5AHD3sbYK4Kq3OcUAdBRXmv9t/Hf/oj/hT/AML4f/IVH9t/Hf8A6I/4U/8AC+H/AMhUAelUV5r/AG38d/8Aoj/hT/wvh/8AIVH9t/Hf/oj/AIU/8L4f/IVAHpVI6iRSCAQRggjrXm39t/Hf/oj/AIU/8L4f/IVH9t/Hf/oj/hT/AML4f/IVAHowtY12YjQeUMJ8o+QdOPSoZ9Dsro25ls7WT7I/mQbolPkt/eXj5T7ivP8A+2/jv/0R/wAKf+F8P/kKj+2/jv8A9Ef8Kf8AhfD/AOQqAPQ9R0231eye2u4Ibq3lGHimQOjj0IPBqObQLG4ukneytHmjjMKSNCpZEPVQcZC8DjpXAf238d/+iP8AhT/wvh/8hUf238d/+iP+FP8Awvh/8hUAejxW0cMjskaK0mCxVcFsetUz4X0xrGe1/s6x+zXTmSeH7OmyZjyWZcYJ46muE/tv47/9Ef8ACn/hfD/5Co/tv47/APRH/Cn/AIXw/wDkKgD0NdNt0K4t4RsbeuIx8p6ZHvST6XbXV7DcyW8Elxb58qVowXiz12nqM+1ea6x4w+OWh6RdXs/wg8LCCzheeQr49BIVQWOB9i9BWd8Ofiv8Z/in8PdC8T6T8IvDL6V4j0631SyaTx1sdoJ41ljLKbLg7WGR2oA9fW0iQjEUY2sXGFHBPU/Xk0k1jDcyh5IYndeAzICRznr9a86/tv47/wDRH/Cn/hfD/wCQqP7b+O//AER/wp/4Xw/+QqAPQb7RrPVLWWC5tLa4hmOZI5YldZD6kEYPQVM9vHJD5bIjR8fKVyOOnFecf238d/8Aoj/hT/wvh/8AIVH9t/Hf/oj/AIU/8L4f/IVAHoxtIic+VHkuHJ2jlh3+vvUFroFjZb/JsrSLzWZ32Qqu9m+8Tgck9z3rgP7b+O//AER/wp/4Xw/+QqP7b+O//RH/AAp/4Xw/+QqAPRre0itARFFHEDjIRQM44HSpK81/tv47/wDRH/Cn/hfD/wCQqP7b+O//AER/wp/4Xw/+QqAPSqK81/tv47/9Ef8ACn/hfD/5Co/tv47/APRH/Cn/AIXw/wDkKgD0qivNf7b+O/8A0R/wp/4Xw/8AkKj+2/jv/wBEf8Kf+F8P/kKgDR/ZN/5Oh+PH/X5of/puWvoWvC/2Q/hf438MePviT4p8baNpHh648ZXlg9pYWGrHUvKjtrRYSzyeVEMs2SAAcDvXulABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAYfxM/5Jv4g/wCwbc/+imrif2HP+TKfg/8A9iRov/pBDXbfEz/km/iD/sG3P/opq4n9hz/kyn4P/wDYkaL/AOkENAHqVFFFABRXj/7TP7Wcf7P/AI58A+FLPQjr3if4jXd1baVDPqMWm2a/ZohLKZLiQEBsFQiKrO5JwMAkczo//BRbw1p3jbwf4X8baHrXw58S+KI9XkmtNfeC3i0xNOZVklaUuFkgl3boZUBR1ViSu0ikpJ7ef4av7uo+V/18/wDJn0NRXk1n+3d8GL7w3qWsJ8UPA66Zo7W6XtzJq8MaW32jP2csWYcS4Plt0fB2k0ms/t1/CDRvh5B4of4jeDv7HvJ7i0tZzqkSie4gXdND1yGjHLgj5AQWwKJSUU5S6Ak20l1PWqK8E+Fv/BSD4WeNPhD4K8UeIPFXh3wVdeNdIttZg0vVNViE9pDO2yNpDwFVnBVXbarMCASRXSa5+3T8G/DWvazpV98TfBVvqfh6ZbbUrQ6rEZrOZn8sQugORKX42Y3e1VJOMuV76r5rf7hbq/p+O33nq9FfOHwI/wCClXgz43B777RoOjeHA+rLHqdz4htm+0JY6gtiJo4uGeGVnVhKMqu5VJywrt7z9uv4NWOjm/f4n+CWtVupLEtHq0Mh8+JBJLHtUltyIys4x8qsCcA0vsqXRq/yHZ8zj1Tt80esUV876p/wUp8AXHxWvfCOgajo2t3lnaaHfpenXbS2sL6DVLloYjbzFyJXUBH2ADf50SqSXFd5a/tnfCW91jWbCP4keDGu/D8Fzdain9rQj7LFbHFzITuxthPEhBIjPDYNGyu/P8N/uFbXl9Px2+89Morifg/+0j4B/aB/tD/hCPGHh3xUdK8v7WNMvkuDbiQFo2YKfuOASrfdYA4JxXbU2mtwunsFFFFIAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAw/iZ/yTfxB/wBg25/9FNXE/sOf8mU/B/8A7EjRf/SCGsn/AIKI/HPV/wBmn9if4jeO9E8NjxZd+GtHku5NMN0bbzbfIWeTzAj7fKiaSU/KciMjjORw3/BGf486r+0f/wAE2vhd4j1Tw2PDIi0pNHs4PtZuTd29kPsa3JJRNvmmFmC4OAR8xzmjqHQ+oaKKKAPEP2w/gV4t+M8vh3+x7H4d+MvDVk06654K8b2MbaXrm9V8mdbr7NcS280LBsYidWEjAjIUj5vn/wCCXnxW8OeEfDq+GPEfgTTdR02LxbbwadcPc3WleFYNZitlgtrETQyGeG2a3J2SpGrea2FQAJX3/RUezWvnf7nv/wAPulomkX7RqUZfy6r11/z9H1ufnpon/BLH4o6v8VovEmual4Ugja68JTTW03izVfEEuNI1J7qfbLdWyBVlRzsijSOJD8u3q57L/h3r8SPh9+0X4j+Jnhi78CazqOt6x4k26RrN7dW1oLDVYrAJKZI7eUrcRSWXzRiMrIj7fMQ8j7Zoq3qrf4//ACe3N9/Kl5LaxC0lzdfd/wDJL8v3X+b3PzT8Uf8ABI/406j+zqPh3D4k8E3FlL4H0vw4ksXiHUtHh0+6tfM85pILW2zqUMm4bBdSBYucRP0PsVt/wT88deFEs/EGk3vhC88VaB8WdR+Iljp93eXEGnajbXlq9q1tNOsDvFMqSMyyCGUKVHBBOPsqiqcm5up1d398lP8AOK+SsDScVF7L/wCR5P8A0l/fqfn14J/4Jy/Hz4T3F54i8K6/8MdL8ZahpviWy8xLy8W2019X1uC/8yBjasS0UKSKpdMCQoSrKCDvah+wL8VLPwx4J0Pw5pXgXwv4f8MWOo2V7ZWfj/VIr/Vri78pjqU2qQabDdvJ5iytLArIs5kBaQbQB9z0VnyL2apfZSsvTXT/AMmfz13Sarnlzup1bu/XTX8F+K2bT/Ofwd/wSR+J3hnw34X0eTWvAkttY6J4M07Up0v7xZI5dB1eS8kMK/Z/nWaGUhSzIVdQCCDuF7xL/wAEo/iZ4v8AgD4c+GVxrHgGz0X4baJ4j03w7q1vcXTXuvSalaXFrCbyIwBbVUWctJ5ck5kdFICdK/QqiqqN1IyjPaTk36y/y6BCbjJTjulFfKOi/wCCeG/Av9l/WPhX+0z4h8aXV3pMml6t4K0DwzBb27P50c+ntdmVyCgURsLhNuDn5TkDjPuVFFXUqSnLml5/i2/zZnGKjt5L7kor8EgoooqCgooooAKKKKACiiigAooooAKKKKACiiigAorzSf8AbL+Elr8XR4Ak+JngRPGxnFqNCbXLYX/nnpD5W/d5hz9zG72ru9A8W6V4s+2/2Xqen6l/Zt09jd/ZbhJvstwgBeGTaTskUMuVOCNwyOaFqrrYHo7Pc0KKKxfiF8RtA+Evg698Q+KNZ0zw9oOmqHu9Q1G5S2trZSwUF5HIVQWYDk9SKTaSuxpNuyNqiobC/h1SxhubaWOe3uI1liljbcsiMMhge4IINTVTTTsxJ3V0FFcD4O/an+GvxD8SWGj6D498I6xquqtdJZWdnqsM092bY4uAiKxLeUeHx93viu+pLVKS2YdWuwUVU17XrLwtod5qepXdvYadp0D3N1c3Egjit4kUs7ux4VVUEkngAVjWfxj8JX/w2t/GUXibQG8JXcCXMOtfb4hp8sTkBXE5bYVJIAOcHIo/r7wOkooqvquq2uhaZcXt7cwWdnaRtNPPPII4oUUZZmY4CqACSTwMUNpK7BXeiLFeWftS/tC6n8A7DwdDofhiHxXrnjfxB/wj9hZz6p/ZsEbiwvb5pJJvKlIAjspAAEOWZegya9K0fWLTxDpNrf2F1b31jfQpcW1zbyCWK4jcBldGUkMrAggg4IIrwj9uH/ko37O//ZSZv/UX8QUO60YJ3V0V/wDhpT42/wDRF/B//hw2/wDldR/w0p8bf+iL+D//AA4bf/K6u8ooA4P/AIaU+Nv/AERfwf8A+HDb/wCV1H/DSnxt/wCiL+D/APw4bf8AyurvKKAOD/4aU+Nv/RF/B/8A4cNv/ldR/wANKfG3/oi/g/8A8OG3/wArq7yigDg/+GlPjb/0Rfwf/wCHDb/5XUf8NKfG3/oi/g//AMOG3/yuroYPiV4cudfttKj1/RZNUvXuI7ezW+iNxcNb7RcKibtzGLeu8AfJuGcZFbdHS4HB/wDDSnxt/wCiL+D/APw4bf8Ayuo/4aU+Nv8A0Rfwf/4cNv8A5XV3lFAHB/8ADSnxt/6Iv4P/APDht/8AK6j/AIaU+Nv/AERfwf8A+HDb/wCV1dlpWuWWuxzNY3lreLbzPbSmCVZBFKhw8bYJwyngg8jvVqgDyj4lfFb4ufFb4da/4X1b4J+EJdK8SabcaVeoPiG3zwTxNFIP+Qb3VjWF+zP4h+Lf7Mn7PPgr4e6V8GfBklh4M0W10iOVfHzRfaTDEqNMV/s44aRgznk8seT1r2mfXbK11i30+S8tY7+7jeWC2aVRNMibQ7KmckLuXJA43DPWrdAHB/8ADSnxt/6Iv4P/APDht/8AK6j/AIaU+Nv/AERfwf8A+HDb/wCV1d5WJr3xL8OeFr8Wup6/omnXRlt4BDdX0UMhkuHMdum1mB3SurKg6uykLkijyDpc57/hpT42/wDRF/B//hw2/wDldR/w0p8bf+iL+D//AA4bf/K6u8ooA4P/AIaU+Nv/AERfwf8A+HDb/wCV1H/DSnxt/wCiL+D/APw4bf8AyurvKq61rdn4b0qe/wBRu7WwsbVDJPcXMqxRQqOrMzEAD3JoA43/AIaU+Nv/AERfwf8A+HDb/wCV1H/DSnxt/wCiL+D/APw4bf8AyuruwdwyKWgDg/8AhpT42/8ARF/B/wD4cNv/AJXUf8NKfG3/AKIv4P8A/Dht/wDK6u8ooA4P/hpT42/9EX8H/wDhw2/+V1H/AA0p8bf+iL+D/wDw4bf/ACurvKKAM/8AZj/aO1v42eIfGmieJfCNr4R1vwXdWsE8NrrP9qQXCXFuJkdZPJhIOCQVK9uteuV89fsm/wDJ0Px4/wCvzQ//AE3LX0LQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAfjN8TPAHirwR+0lrVp4D+H3xEl1bU/iqNavfh34q8BJr2g37ySBX12z1sQr9kiAZmU+YShwScDjD+Guj+N/wBnj4L+IPBdlp37ROmarefFvVxqd3pl3r1jp9pahZDZzSvaWktzcC4O44tHjMrLEZZMbc/trRWUadqap36W+V6f/wAr+V3aySRpOpzTc33v87T/APk7/JXu22fi58Nbb9qL40+BdEj8U63+0Xol1ofwR13Ud1lPqumS3fiC11O+WxS4KhWluXgEB2MfMlUJncDzy/7Xcfx3+NHwY8aaL8SIP2htR13Vfh74Rk8FaJommalJpOr3BhgfVzqEEEZiNwkwct9oAdSOOdgr9y6K1qpVL36//JTd/X3kv8MUvQhU5HzLp/8AaWXp7n/kzPx3ufil8eIP2yfCg8O2Px+0i00vxrY6Jq2m302r3WmPpH2RYmuEtorWLTrezY8oWeW43BmZwBTPBXgj44+Bf2fvgD4r8feN/wBqV9D8b67fn4nLZ6jq82q6HHC86ackMEStdW8Mmf3uwfvMR+qiv2LoqpSbu3u2n91rr5tXfn5aGcdPd6Wt+Ekn8r6ei7H4bfsleG/il8BtG8C3Or+DP2h4/ClraeNL3VLDR9O1Gx1m7mkmX7HvaNVaO4kYjDcdXIyAa2tI8UfH20+B3hm+m8V/tHH/AISLxct547tJ7bxTAfBullJfsVnb3T25u5EDb/tM1ruJIiU8bWb9r6Kz5bRjD+VRXyjLm/HRPyVlZN3bd3KX8zb++PLp6brz1d7I/Fz4kXv7QHiD4deHNG+KOq/tE3vhPUvhhrcOgN4d0nU4L/Wtea5mW1ttXhhVpXJtii4uQquBuPVyfVP2oP2fPFWvf8G/fwf0ZtA8Zxa94THh+71DSbO0uk1CCNJ1SbzLZF8wmNXL4K5UqG6qK/U+iq6afzRl/wCAylJX735rN6aJA3d69pLT+9FRduy0ulrq2fkX4a8W/H++/beMZ1/422WlReL7JdEtrq01ybTL7wf9m/1lwhjW3WRoyDLPLILpJyBjcDjz3UvC3x0+NXw4+P3hvxeP2mtT8KXvhHVJ/hXbazFfIupwRX0kjJqKoDI92yIFijuuXiyAvzR1+21FZypp0/Z/3WtfONrvzVr37uTt72lqpaXNbrF/+Atuy7J3t6KK6HjH/BPC3t7P9iH4Yw2zeJWWDQLaKQa/HdR30cqrtlRluVWUIsgZUBG3Yqbfl21jftw/8lG/Z3/7KTN/6i/iCvoCvn/9uH/ko37O/wD2Umb/ANRfxBXRXq+0qSqd3c5qNP2dONNdFY7SiiiszUKKKKACkIyKWigD8xfg18AL7X/jt4Z0hpPiTov9j+I/iNNfXNrd39lPAJLiB7Qi5OGCyqA+UYeaV5LZYGjpnxn+PHiHwzp1x4j17xvofiMeFNAk8KskOoRG/vnB+2O9nb2zxX0xkXbLHcMvlx/MAmS9fqRRRT9yMY/yqK+7m+5u/wCBc58zk2t3J/8AgUua3mv8z5s/bV8TazpHjb4WWusax4r8OfDm/bUD4r1Lw41xBNHdJbI1lHJPbgzQwtJ5xypUMyRoxIbaflf4n/tE/ER7xJ/D1z8brfUNDn8PR6afEtxdWmo3tpJLAbic6VZ2QtZomiZxLNdTFkcEBY2wp/TuiiOkuZ97/j/S9NNSPscvlY+Pf2QNB1PwF+yX8btO02fxho3iaz8TeKZLeR7G5v7y1Z7m4e2uLeCb/j4ZlKSAIT5p6kk14j4c+PfjnSvAraLdS/EzUbC71nSYZ/EEHivU4dEYPbXTTLLezac+pWJLxR+dDE0mySSFEliDMD+mFFJK1r9oL/wD/Pr+N7IucuZt93N/+Ba/h0/C12fnN+xZe+K/F37U/wAKfEfjc+O5Jrex8YaHa3eopqO1VTU7ZrKGZpURjutwxDTqrSCNS2WUY6z4/wDxF+I2n/Gf4jC31X4hWnjvTfE+jQfDzQ9NiuW0fVNJf7L9pkkjVPs86EvdedJKS0OxcNHxu+7aKuLsqa/l/H3uZv1eqb1um11Ilq5v+b8NLW9NtO6Wp8O/swT/ABKs/if8JNc1bXviJfN4v1/xbY+IrPU7ieWwhs7aW5/s/EDDZBgRx7JAFZw+CzAgDhP2zPhDfeI/22fF9vBD42hfxDrPgCa2urL7WYxDFqMwupopADErQZjOese9iMZY1+jtFTGylCX8rT+5p2+bWop3lGpH+e/yu7/gtD85vF/jL4qeEPFw8NanrfjuH4Y6P4z8RWLatdapqVtcmGK3tZNPim1G3hluzFukutjHiRo1RnbG0+ueOPEfxRuf+CaHhG4bWvFf/Cd6hf6NbXWp2lhJZaq1tLqkMbyPEUDRv9lYlyyD+IlRX17RRDSMYy1tyX8+Xe/+Lr5dyn8XMv73yu3t6X/4Y/PqCL4nfCrxbJrNn4h+L2tQ6L8W7zw3aafLeXN+svh8abNOB5cu5Z2M+AlxLuYHYm/HFeK+PvGPxD+MXwy8VaUzfEfU9F1n4eHVryzm1TVdYkbVYtSszslZ7S3jhuVhafzLW1Tyl2/d4Br9b6KmmnFWlrpbX/By/i/ff97XfUJu7utNf/b+b8vd/wAP3GV4GuLW78F6TLYzXNxZSWcTQS3JkM0iFBtLmT59xGM7/mz15rVooq5O7uRCPLFR7BRRRSKCiiigDhv2Tf8Ak6H48f8AX5of/puWvoWvnr9k3/k6H48f9fmh/wDpuWvoWgAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK8g/a6+B/ij4xQeAL/wffaDZa34D8TnxBGmsxyta3atpmoWDRkxfOpxfbwf+meO+a9fooA+cP+Fe/tE/8/HwW/LU6P8AhXv7RP8Az8fBb8tTr6PooA+cP+Fe/tE/8/HwW/LU6P8AhXv7RP8Az8fBb8tTr6PooA+cP+Fe/tE/8/HwW/LU6P8AhXv7RP8Az8fBb8tTr6PooA+cP+Fe/tE/8/HwW/LU6P8AhXv7RP8Az8fBb8tTr6PooA+cP+Fe/tE/8/HwW/LU6P8AhXv7RP8Az8fBb8tTr6PooA+cP+Fe/tE/8/HwW/LU6P8AhXv7RP8Az8fBb8tTr6PooA+ZPEPhX9ofw9oF9fvL8GJEsbeS4ZFGp5YIpYgflWP8G5f2gvjH8IfCvi62Hwbs7fxVo9prEVvL/aTPAlxCkyoxHBIDgHHpX0v8TP8Akm/iD/sG3P8A6KauJ/Yc/wCTKfg//wBiRov/AKQQ0AcF/wAK9/aJ/wCfj4LflqdH/Cvf2if+fj4LflqdfR9FAHzh/wAK9/aJ/wCfj4LflqdH/Cvf2if+fj4LflqdfR9FAHzh/wAK9/aJ/wCfj4LflqdH/Cvf2if+fj4LflqdfR9FAHzh/wAK9/aJ/wCfj4LflqdH/Cvf2if+fj4LflqdfR9FAHzh/wAK9/aJ/wCfj4LflqdH/Cvf2if+fj4LflqdfR9FAHzh/wAK9/aJ/wCfj4LflqdH/Cvf2if+fj4LflqdfR9FAHi/7KXwK8YfDHxb4/8AEnjbUPDV1q/jW8s5Vg0OKdba1itrZYVy0x3MzHJPAA46549ooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDD+Jn/ACTfxB/2Dbn/ANFNXE/sOf8AJlPwf/7EjRf/AEghrtviZ/yTfxB/2Dbn/wBFNXE/sOf8mU/B/wD7EjRf/SCGgD1KiiigDwv9vL9qTxh+x78IL/x3ovgnw14w8PaLFG2pLe+KJ9JvUeSeOGMQxpYXCSDMgJLSR4AOA1P8KftxeG9J8Tx+E/iFqXhXwx45+2w2FxY6PqN5rGmWU1wA1rBNqD2VtFFcTKQVhkCO2Rt3ZFbf7bv7Olz+1l+zD4n+H9nqcGjXGvi2CXk0JlSHyrmKY5UEE5EZHXvXjnj/AP4Jz+JvE+t+O9CsvF2iW3w++JXjPTvG+rifTpJNYtJ7VrN5LWB/MERSVrKLEjDMQLLsfIIKPx8s9r7+V4/o5PZ7WtdhP4bx31/LT8el1vukjsfgd/wUq+HvxL+EjeJPEWqaX4Ou7K0vNS1TT5bxroaTaQX01mk00ojVU814TsVgrOTtQORmt6f/AIKG/B+00GK/l8WtE02qDRFsJNIvl1T7cYTOtsbEw/ahK0QLopiBdeVzmvmbQv8Agihqfg74T+JPCui+PraxtPHDrquvI9nNJFJrFtqn26xvIgJVdB5YW3mRWXcqI6lWXn0X4e/8E3dc0v43+GvH+sa14cg1XSPFia/dW1hHe3Rnt4tKurCKBrq7mkmlfdctJvbAUfIFwA1KleUVz6PT80n+F7eiel+VOdlfl13t911+On4dOZ+peG/27fBHjPxJaf2Lqthrfh2/0Aa5b3empe3mov8A6Y1qwNlHasyxrIjKzlw6urK0Yxuplx/wUc+DUGkC9Hi950M93AYbbRr+e6jNoVF27wJAZVigLqskrKEjY4ZgcivBtJ/4JafEXwBp9+PCPxM0vRb/AFfRL/w/dX0djKlzDa3mvXWqTG3kDHypfKuBCshVtpy4GcAbXxH/AOCdXjzxR4Y8O+G9A8ReF/CXg3QPDl34ct/DumXWrWlhAZdhS+k+z3EL3ki4cNDcMY33lydxOY5p+zulr72nzlb8OVLzevKld1aPtGm/dvv5Wj+vM/JKyu2ku3T/AIKaeEtd+K2reG9FSyuLXTbnw7FDrN/dXFrYapHq7EI1vIltIrOFMZjViqzFyA6KpeustP8Agot8Fr2z1a5Hj3To7PRrGbU5rqa2uIba5tIZBHNcW0rxhLqKNyFZ7cyKpIBIr550n/gkN4kttD03RbnxvokmjpbeC470xafNHdGTw/hD5TeYQBNHuxkZRiOoHMXi/wD4JG+M/iP8DPDXw/1jx54aTSfhx4R1Hwn4ZubPR5UuLxbtIYRc3gaUhTHDDt8uLh3Jfcowg3aV5xT2lKz7q2j/APAum7vurGdO7cefS6jfyd9V56fdbrc+uvgj+014I/aK/tZfCGtf2lNoUkUd/by2dxZXFr5qeZEzRToj7JE+ZH27XXlSRXeV5X8J/wBne5+HH7R/xH8cyalBc2/jmy0a0htEhKvafYYJYmLNnDbzJkYHGK9UqXa+hNNyavJWf9f8MFFFFIsKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiivGv2xfjF4w+F0Xw60vwRN4as9a8e+KzoBvdc06fUbWyiXS9Rv2fyIbi3Z2JsVQfvQB5hODjFAHstFfNn2/wDaO/6KB8Ev/Dcap/8ALyj7f+0d/wBFA+CX/huNU/8Al5QB9J0V82fb/wBo7/ooHwS/8Nxqn/y8o+3/ALR3/RQPgl/4bjVP/l5QB9J0V82fb/2jv+igfBL/AMNxqn/y8o+3/tHf9FA+CX/huNU/+XlAH0nRXzZ9v/aO/wCigfBL/wANxqn/AMvKPt/7R3/RQPgl/wCG41T/AOXlAH0nRXzZ9v8A2jv+igfBL/w3Gqf/AC8o+3/tHf8ARQPgl/4bjVP/AJeUAfSdFfNn2/8AaO/6KB8Ev/Dcap/8vKPt/wC0d/0UD4Jf+G41T/5eUAdF/wAFK/HXjH4XfsE/FbxN4B+w/wDCUeHfD1xqduLyDz4WhhAkuQUyMk26zAc/eIPPSuI/4IpeOPGnxI/4Jj/CjWvHLWH9pXekrFYxWtqbcQ6dCxgtAwJO52hiRy3APmDjjJseJNO/aC8W+Hr/AErUPHPwQubDU7aS0uYW+HGqbZYpFKOp/wCJ50Kkj8ayvhD8Pvjx8EPhR4Z8GaD48+C0WieE9KttHsEf4c6kXEFvEsUe4jWwC21RkgDJzxQB9a0V82fb/wBo7/ooHwS/8Nxqn/y8o+3/ALR3/RQPgl/4bjVP/l5QB9J0V82fb/2jv+igfBL/AMNxqn/y8o+3/tHf9FA+CX/huNU/+XlAH0nRXzZ9v/aO/wCigfBL/wANxqn/AMvKPt/7R3/RQPgl/wCG41T/AOXlAH0nRXzZ9v8A2jv+igfBL/w3Gqf/AC8o+3/tHf8ARQPgl/4bjVP/AJeUAfSdFfNn2/8AaO/6KB8Ev/Dcap/8vKPt/wC0d/0UD4Jf+G41T/5eUAfSdFfNn2/9o7/ooHwS/wDDcap/8vKPt/7R3/RQPgl/4bjVP/l5QB9J0V4f+yR8YvHfjrxx8RvDHj278JalqHgu8sY7a+0DSbjS4biK5tVmw8M11cncrEjIkwRjgV7hQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFfNXi3/gqn8OvBXxxPw4vPD3xbbxixla306DwFqk0t9DFIY3uYAsJ823yp/fJlMc5xX0rXxz+0P8Asp/Ebx//AMFTfCvxF8O2f2Lwxp/wy1Xw6fEH2uAf2bqU7TeR+5L+c2C6NuVCvvWU5yjJNK696/yi5LXzaUfmXGKcXrZ+7b5ySf3Jt/I+oPip8W9E+DXwx8ReLtduXh0XwrYTanqTxRmWSCGJDI52D5idoJx1NWfh78RtK+J/w80TxRpM5fR/EGnQ6rZySqYma3ljWRGZTyvysMg9M1+Qng3/AIJXfHGHwfa6dpnwsPgvxJpHw/8AFOheMtcPiSyuP+Fo399FKtmAROWb94yS+ZdCPZ93jaKraT/wSU/aE8Efs4av4LufCK+KLq513wx4m1LVv7WsDfeJNOt7ZY7nw7Ks87IRZyBTErn7NIsZ+bIRTr3v/dt85yi//JUp62stGrtCsrL/ALev90WvnduOl0907Rlb9nWuo0t/NMiCLbu3lhtx659KSS8iiaMNLGpmOIwWA3/T1r8mvhr/AMEkPHHiX4gfBaHxb8M55vhxoms+L9R1LQtd1jSrxNCgvbaP7FF5FuUjRHuI/MWCDzlhLcvjp5p4h/4JPfHqD4OfC+B/hbf6z4u8M+FDo3lX+raHrelQSJq01zFbSxXE0UtiPLZSbqxuZGKhY9gywo7N9bfJPm/LlWn95dbJjVtv61t+Wv8AwNV+2tfP/wC3D/yUb9nf/spM3/qL+IK9t8GR6hD4P0pdWS2i1VbOEXqWzs8KT7B5gRmyxUNnBbkjGea8S/bh/wCSjfs7/wDZSZv/AFF/EFOa5ZNGcJc0VJnaVS8S+IbXwl4cv9VvnaOy0y2ku7h1QuUjjUuxCqCTwDwBk1dqO6tY722khmjSWGVSkkbqGV1IwQQeCCO1RLm5Xy7lxtdc2x4b4P8A+ClPwa8d+EJdc07xY8thFbX15l9Lu43eGys4b25dVaIEhILiFunJcKMtkV7T4b8Q2vi3w7YarYSGax1O2ju7eQqV3xyKHU4OCMgjg818Yf8ABQ39h9/GHirw5eeAPhVo+pRx+EPFWiztpdnp9obS8u7CGGwdvMaM4VkdQy7imegBrzn4jf8ABPPxx4UddP8ABHgoad4MudD8Iv4l0bTZrRE8Qz2k9ydRjeF5VjuJijQs5lYLOE2l2zinCSk7NW1S9Pju35Win5XW99G42gpX1tJ/c4pJeer9bN6WPtT4+/theAP2ZNe0DTPGer3GmXnicsumpHYXFz9oKzQQkZjRgD5lxCOcffz0Bx1nxZ+KmifBD4a614u8SXT2Wg+H7Vry/uEgeYwxL95tiAs2PYE14X+w7+y7a+Fvh/ra+J/BX2Gyk8R3GoeHtK1y1sJTo9s3kN/o0EIeOyjeaFZRArtsZQflOAvr/wAOPHui/tLfDW/nm0K5/se4vL7Rrqw1m3gkW7FvPJby5VXkjkido22nJDKRkA5FU17tutr/AH209U3Z/oTFq95bXt+e3qldfqWvgn8b/Df7Q3gGLxN4TvZNR0aa5uLRJ3tpIC0kEzwyjbIqtxIjDOMHHGRXS6tqtvoel3N7dyrBa2cTTzSN0jRQWZj9ADXxz+07+y9K/wC0HrGpy/Bhvij4Su/C0Nl4W0zTb220uDQdXN5PPdS+YZI3spJzJE5vIFaQeW3OSA3jN9+xr8SvHfxn07ULz4QwaVPca54gXxDcx/ZbiK8sbm0u4bZZ9Qub2W7v0kLwNsKJFFjAiTaBWc5NxvBa2f3p2Xbff077lxglK032/K/4fD6n2f4D/b8+FfxN+Kmi+DND8RT32v8AiGxh1LT4Rpl1GlxbzWn2yOTe0YVQYPm+YgjoQG4ro/2jv2pfBP7J3hG01zx1qsukaZfXLWkMyWU1zukWGWcgiJGI/dwyHkfw46kCvLf2Ufhzov7Kv7DfhbX/ABB8NLXw94p8BeFFOrQQ2enDU3mtrdluGSdJPKJlIkYM0w3CT5ipLAe4T6HoHxs8D6ZPrXh+01LT7+3S9jstZsY5mg82Egh43DBX8uR0b2ZhkgmtsRDlnKFJ35Xv5XdvvSZlQleMZVVa6enmkr/i1/n1Njw9rtt4o0Cx1OzZns9Rt47qBmQoWjdQykqQCOCOCMisz4lfFDQfg/4X/trxHqCaZpn2m3s/OaN3zNPMkMKBUBYlpJEXp35wOa+DvGv7K3xI8KftHeMNe8G/C2TVrrUr3WpvtOrXtva7reawljgFrq1ndW90IXkEUS2c8TiAHcskexXrzi9/YF8f6/Za/wDZ/g0sGiy6V4ZuF0qPTtK0yG+v7PVlkvDHbm9mLS/ZHlj8+5l8yVd4LkMN0QkpyjbRO2/RO7d/RLe271S2LcXFNN3avt11S/W/orptan6E/BX9sLwB+0J488Q+GvCmsT6hrHhUsNThewuLcW5W5mtj80iKrfvbeZflJ+5noQSfFr9sHwB8D/ip4d8F+JNXnsfEXivyv7MtksLiZbjzblLZPnRCi/vZEB3EYBycDmneItV8Ifs1aPper2PghNPm8U6rYaJJFounWkN0kl1cMEMwDpvSOWeR32FyN8jhW+Y10PxP+Fun+PNKubldL0WTxLb2ckWk6ld2UcsunzffidHKll2yrG/ynqgPUClJ8sVK11HSVutldqPbddwVpSaWl/hv0vpr32fY6uvNf2k/2t/Af7JGhadqXjzV5tHstVkmitpI7Ge63tFC87giJGIxHG5564wMnivgfxB+wr8Sdf8Aglp+i+GvhfqnhPxFbeBrnRvHN6+pWcZ8c6q9xZtHL5kc7NcOGjuZ/tE20qsuwNnKD6r/AGdf2L9F+Hfxo+LNnd+APDtr8PdTuNKufDtg9nbS2Il/s97e9kig5ETOWKu21TJubO4E1TVna/8ASk1+KV167CTV9V/Vl69XbTs9b6H0D4j8b6d4U8DX3iO+lkh0nTbGTUriUQuzJAkZkZtgBYkKCdoGe2M15H4Q/wCCj3wd8c+FLnWdO8VPLZWtnqOoOW0y7RzBYQQz3bhTGCRHHPEf9ovhckED0H4dfEvTPjNB4rsE0i+gtvD2r3Hh27jv4oWhvmjRC7R7HdXhIkC/NhgQysqkEV8q/t8/sRzeK/iNpmo+BPhZpOowyeAfFOgNNplpp9qbO/urWJLJn8x4zjIlUOm4pvPQMTWNScleUVdON4+vK5K/dPRdNXua0IRk4xm7NO0vvSdu1tX12Ps7w34htfFvh2w1WwkM1jqdtHd28hUrvjkUOpwcEZBHB5rz745ftheAP2cfF/h/QvF2sT6dqfikgabFHYXFwLgm4gtsbo0YL+9uYV+Yj7+egJHxX8Rv+Cefjjwo66f4I8FDTvBlzofhF/EujabNaIniGe0nuTqMbwvKsdxMUaFnMrBZwm0u2cV9F/sM/suWnhHwPrLeJfBI0+3bxHcah4d03W7WwkfRrZjbuPs0EAaOyieaBZhArnYyq3ynAXq5Yuo9fdTfq0mlp63un1Senbnu1BX3aXom4319Nmuje57l8YPi3oPwI+GmseL/ABPdvYaBoMH2m9uEgknMMeQudkYZjyR0BqP4M/Gbw98fvh9a+KPC15Jf6LeyzwQzvbyQF2hmeGT5JFVuJI2GcYOMjIINUfhr470T9pv4USX82g3A0bUbi70+bTtatoJPPFvcSW7llV5InjZoiykMQylT3xXyL+27/wAE/dT+LPxC+JeoeHfAdhcR/wDCD6XZeEJrY21t9i1RdUuJ7l7YFl8ibY4Yy4UnewDHcwOOvMl3v+Cb/G1l5s1smnrt/mo/hdt76L5n3jXnPxk/aw8BfAO6vbfxRrZsbnTtOi1a4hjs57h47WW7js0lIjRuDPKi469TjAJHxl8SP2JfE3gf4weItK0L4Rabqfwnv/E1rqNpZRWttf2lrt0WKF5Y9Le8t7aRnut4Z7hXCMPMCZO8aP7BP7E3iTwF8U/A+ofEf4Vwyxr4Hu9Eu7u+TTb3+zLuPV557dZcSsSPsnlIjRBwo2r8oHCV5SSjovP/AAOX/pSUfn5oibtT5lvp+Mkv/Sbvyfofbnwd+L2g/Hr4aaV4u8L3cl/oOtxtNZ3D28kBlUOyE7JArDlT1A9a6aqegeH7Dwpo8Gn6XY2mm2FquyC2tYVhhhXrhUUAAZJ6CrlW7X0GcN+yb/ydD8eP+vzQ/wD03LX0LXz1+yb/AMnQ/Hj/AK/ND/8ATctfQtIAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK+f/wBuH/ko37O//ZSZv/UX8QV9AV5n+0x+zo37Q2neFDa+J9V8I6t4N1z+39N1Cwt7e4ZZjZXdkyvHOjoyGG9l7ZDBTnjBACiuI/4ZB+Iv/RffFf8A4TWjf/I1H/DIPxF/6L74r/8ACa0b/wCRqAO3oriP+GQfiL/0X3xX/wCE1o3/AMjUf8Mg/EX/AKL74r/8JrRv/kagDt6K4j/hkH4i/wDRffFf/hNaN/8AI1H/AAyD8Rf+i++K/wDwmtG/+RqAO3oriP8AhkH4i/8ARffFf/hNaN/8jUf8Mg/EX/ovviv/AMJrRv8A5GoA7eiuI/4ZB+Iv/RffFf8A4TWjf/I1H/DIPxF/6L74r/8ACa0b/wCRqAO3oriP+GQfiL/0X3xX/wCE1o3/AMjUf8Mg/EX/AKL74r/8JrRv/kagDt6K838X/ssfEjQPCeqX0Xx88VNJZWks6BvDWjYJRCwz/o3tXP8A7O3wG+J/xe/Z98C+LL748eJoL3xR4e0/V7iKLw1o/lxyXFtHKyrm2zgFyBQB7RRXEf8ADIPxF/6L74r/APCa0b/5Go/4ZB+Iv/RffFf/AITWjf8AyNQB29FcR/wyD8Rf+i++K/8AwmtG/wDkaj/hkH4i/wDRffFf/hNaN/8AI1AHb0VxH/DIPxF/6L74r/8ACa0b/wCRqP8AhkH4i/8ARffFf/hNaN/8jUAdvRXEf8Mg/EX/AKL74r/8JrRv/kaj/hkH4i/9F98V/wDhNaN/8jUAdvRXEf8ADIPxF/6L74r/APCa0b/5Go/4ZB+Iv/RffFf/AITWjf8AyNQB29FcR/wyD8Rf+i++K/8AwmtG/wDkaj/hkH4i/wDRffFf/hNaN/8AI1ADf2Tf+Tofjx/1+aH/AOm5a+ha8r/Zu/Zpn+A2reLdV1Hxdq/jPW/GF1b3F5e31pbWvlrBAIY0SO3REACgkkjJJr1SgAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAMP4mf8k38Qf9g25/9FNXE/sOf8mU/B//ALEjRf8A0ghrtviZ/wAk38Qf9g25/wDRTVxP7Dn/ACZT8H/+xI0X/wBIIaAPUqKKKACivnX9tb9qLWP2a/i18MHt5ZH8N39v4jv9dsYoYmlv4rDSZLuNEdxlG3pwVIz0PFcdH/wVjs9Lto4Nc+HHiPSNd1vStD1fwzpY1GznfW49Yuja2cbSBwkEnmqS4YkKgLBmPFKMlKfJHfRW83eyXm7Oy30YPRcz23+Ssn8ldXe2qPruivgnwz/wVl1P4afFDx34d+ImnWdhrs/jm40Pw9pep63p+lWGkWlrpVjczmbUH2oyl7jMZIaRzOi7VAO3udJ/4K7aF4lt/h//AGX8P/GWoXPxXj2eEo4TA8eo3cVybe9tpZVYxwm22tK0hZo3hG5GY5UVFc3Ly/a5bf8Aby5kv0fS+lwl7t+bpf8A8lbT/L7te59e0V8Q+G/+CrM+iaN4mhg8IeLPHc3hOw1/xNq97Pc6fp/2PTdO1W6s5Y0VdokZfIPlDaC6Ab3DZJ7SL/gqPp+uanBe6J4C8Q6t4JfxdpvgefXxeW0X2bUr3yMZtyxcwxm4jRnBzvyApHzUqf7xpQ1vb8Xyr/yb3b7X0Cp+75ufS119yu/w1tvbU+qqKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDD+Jn/JN/EH/YNuf/RTVxP7Dn/JlPwf/wCxI0X/ANIIa5v/AIKc+AfEnxK/4J//ABZ0zwfreu+H/FCeHbm/0u80e9ls7wz2w+0LCkkbKwEvleUwzgrKwOQSK4P/AIIdeCPEngr/AIJc/CY+K9a1/XNY1vSRq4l1a9lupLe1nJe0gjMjMUiS18gKgwoHQDNAdD6yooooA83+Pv7K/hb9pG90ifxINRL6JaanZ232W48oeXf2jWlxu4OT5Ttt9DzzXH+Mv+Cc/wAOPHQtmvY9cW40/wAOaV4asbmDUDFPYRaZcm5sriJwMrcRyndv5BxgqQSD7xRSUUpcy30/C6T+V3b1HfSz/rVP80vuPnDTP+CY/gzRtWm1218UfEKDxxNrNxrv/CWrqkJ1ZLm4tIrS4AzD9n8qSKGIGMwlFMalQu1cP1v/AIJd/DLxNc6ZeanN4w1TWPDtpaWugate65Lc6h4eaC4Fz59rNJlkmkmAMjtuLqAh/dgJX0ZRTWjTXS1vKysrdrLTQT1un1vfzu7u/fXU+f8Aw9/wTV+G3hqz8WQwf2+w8aaDqvhzU2kvgS1rqV5PeXO3CAK5muJNp/hGBjivHPFH/BMTxXf/ABt0tNGutB0H4dad420fxg32XxBfedeNp8UIHnaa0DQNcyGFVadbpIyuHMBkXJ+46KKfuTU49LfhLmX3S19Qn78ZRlre9/muVv1a0CiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKK8B/wCCgX7aWtfsL/CiXxxF8N9R8b+FtLhafWr201m1sjpQ8yOOPMcvzy72k/5Zg4289ap+A/8AgpD4M0/whoV18Xbzwx8E9e8UKtzpOia94qsJrm8s3RGiusxvhEcsyjfjBQ5og1O6j00+b2++zt3Sb2HJONm+v6b/AHXV/Vd0fRVFeA+A/wDgoh4I8S/Hj4heA9ZurDwve+CNdsfD9lLf6jED4kubq1+0olrHwzOFONi7ie1dVoP7cnwa8U634k03Tvij4Dvb7wfBNda3BDrduzaZDDxNLL83ypGeHbop4JBo6J91f5WTv9zTfa+outvO3zu1+aa87HqlFec/Bb9rz4W/tHa1qGneAfiD4Q8Y32lRrNdwaRqkN28MbHAchGOUzxuHGeM5riNK/wCCiHgHRdQ8ar4813wd8PbLwn4km8N211qPi3TphqkkcYkJ2RyFoJNv/LCUCUf3elG2/a/yul+bQWvt3t87N/kj32ivF/GH/BRD4JeDPhZpnjG6+KXgMaFr/nLpF02twLFqckX+sjjbdyVbCt/cLANjNeafsl/8FZPDP7TWi22tajpWmeBPDcnhF/FtxqGq+KtP32MS3slqyzW28TomYy3nsgiOQoYtxR38t/LRv8ot/wDDoHok++3nql+bX9Jn1nRXjaf8FDvgVJ8L28aD4ufD4+FkvBpzal/bcHkrcldwgPzZ8zbltmM7QWxjmrHi39vr4I+A10FtY+LHw/0+PxParfaVJNrluEvrZm2LOjbseUWBUOTtJBGcg0Wd7ddvm9V+GodL/wBdvzPXK8H/AG5vFXibS5vhNoPhrxVq/g4+NfGraPqOo6XDaSXYtk0TVr3ZH9phmjXM1nDk+WTtDAEZzXu0cizRhlIZWGQQcgivAf24f+Sjfs7/APZSZv8A1F/EFDDfVGD/AMKH8c/9HC/GT/vx4d/+VVH/AAofxz/0cL8ZP+/Hh3/5VV6lRQB5b/wofxz/ANHC/GT/AL8eHf8A5VUf8KH8c/8ARwvxk/78eHf/AJVV6lRQB5b/AMKH8c/9HC/GT/vx4d/+VVH/AAofxz/0cL8ZP+/Hh3/5VV6lRQB5b/wofxz/ANHC/GT/AL8eHf8A5VUf8KH8c/8ARwvxk/78eHf/AJVV6iTgV418LP20dP8AiT8WtP8ACF34M8deEb3XrG91LRZdesobYapb2kyQzOIVmaeDmRGUTxxllYEDPFC1lyrf/LX8k38mGy5jU/4UP45/6OF+Mn/fjw7/APKqj/hQ/jn/AKOF+Mn/AH48O/8AyqrofjX8X/8AhTfhuyvI/DniTxXe6pqEOmWenaJbxyTyzS5wXeV44oowAS0ksiqOBkkgHySz/wCCkXh/XYbOx0jwZ441fxhNeapZXXhiBLFL/TW01kS7aWR7lbfaGliVCkzeY0qBQTuwk07pdP0tf7rq/a+o7PTz/wCDb77O3e2h3X/Ch/HP/Rwvxk/78eHf/lVR/wAKH8c/9HC/GT/vx4d/+VVd34C8Xx/EDwVpWtxWGraXHqtrHdCz1SzezvbXeoPlzQuA0ci5wVPQivJvDP7dOjeLvGdzaWHhHxxc+GbbUL/Sm8Vw2cM2ki4sg/2gtslM8cIeOSMTyRLE0iFQ3KkudoNqXS/4CjeSUo9f1/4Zm63wF8cOpB/aE+MZBGCDb+HOf/KTVTw5+zN4r8I+HrHStM+PXxesdN0y3jtLS2htfDix28MahERR/ZPCqoAA9BU/7L37Vcf7VPhy31zTPA/jDw/4fv7KO/stS1ifSjHdpIFZFEdtezzxuUYNiWNOPfAq98dP2krX4LeJvC3h+38O+IfF3ijxlJcjS9J0f7MsskdtGJJ5nkuZoYkjQMgyXyWkUAHPBNODtLRhH3tit/wofxz/ANHC/GT/AL8eHf8A5VUf8KH8c/8ARwvxk/78eHf/AJVV0vwN+M+jftCfCvSfF+gG5/szV0ZkjuYxHPbujtHJFIoJAdJEdWAJGVOCRzXC6t+2jp/h74zaf4U1LwX470yx1fxAfC1h4gvLKGDT77UPs7XG2JGmFy8RVHAnEPlFlIDY5ot73J1/4KX5tJd2wv7vN0/p/gk79rM1f+FD+Of+jhfjJ/348O//ACqo/wCFD+Of+jhfjJ/348O//KqvQfFvizTvAnhfUNa1e7hsNL0q3e6u7mU4SCJAWZj7AA1414H/AG89J+KvwgsfF3hLwR8Q/Eiar4iufDlppttpaRXYlgkkR55/OkSO1h/dsd07oRlVK7ztpbuy3/zaX5sdmlzPb/gX/JHSf8KH8c/9HC/GT/vx4d/+VVH/AAofxz/0cL8ZP+/Hh3/5VVwd9/wUm0H/AIVNaeNNN8A/EnWdCGl3+sarcW9haxxaFBYztb3KzTS3CQvMrpJiKB5WdULAEFSfoHw3r9t4r8PWGqWbM9nqVtHdQMylS0bqGUkHkcEcGmldXX9b/wCT9bMV7aP+rWv81dXXS6POv+FD+Of+jhfjJ/348O//ACqo/wCFD+Of+jhfjJ/348O//KqvUqKAPLf+FD+Of+jhfjJ/348O/wDyqo/4UP45/wCjhfjJ/wB+PDv/AMqq9SooA8t/4UP45/6OF+Mn/fjw7/8AKqj/AIUP45/6OF+Mn/fjw7/8qq9SooA4r9jDxF4pi+JvxW8J+IvGWveNrbwtfacdPvdYgso7uJLiyWV4ybWCBGXfkjKZGTya+ga+ev2Tf+Tofjx/1+aH/wCm5a+haACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA8R/4KN/sz6z+2L+xX47+G3h690zTtY8U2sUFtc6izrbRFLiKUlyiu2MIRwp5Ir5e/aD/wCCTXxP8WeJfGEvhDXfhxc2PxU+H2l+BfEZ8Rx3Rn0H7HGkZuNP8pGEoYKWCSeXhwrZ4xX6H0Vn7KN2313+6UbfdJotVJJK3Tb74v8AOEX8j80PCX/BD/xt8Jf2tv8Ahbfhnxh4eutZ0vUNKsrBdSlnAvtEj0ldPvlmxC3lXb7Q8ToXAPUisj4Uf8EMfH3gP4f6z4WvdW8AX8GmeFfEPh7wzrb6xrst7K2piVVaS0aQWdnHiTMqxxz72UMMN81fqNRWkveTjLqmvk1y/wCb9ZN9RQlyNOPRp/NO6/y9El0PkH9jj/gnj4k/Zu/aO8J+MdQ1DwzNYaH8H9L+Ht1FYtL509/azLJJOA0agwkA4JIfPVRXm0X/AASO8cn9p+PxrLrng6TSV+NknxMNu0twZjYNbiMQ4MO3zwwzjOz/AGq/QeirlNyqKq91d/fUVX/0tL5aGfIvZul0aS+6Hs//AEl/fqfmh4S/4I6fFn4PeJdC8TeFdc+F9/rVhdeK7KfTdZF2dNj07WZXeOWIpCW+0RBsNGUCOBt3gc1xHhb/AIN9fiLH8KL3w7qXjbwZbzn4e2vhm2mtWupo3v7bXW1RDKjRJm2ddqMQdwJJ2kDn9ZqKypR9lGMYactreVlJL/0qT9X2sjScuaTnLdu787tN/wDpKXoj86/jR/wTA+Nvx71nwx471m++Dmk+OvCviSXU4dH8Nzanolhe2stolu/narbRpeNcL5YZH8r5QWTJU1x/jT/giN8StN8I+E7XwHf/AAy8Ia1p2gf2Xdaxo2t+ItMnsZTfteFdkst5HqNoGdiIZ1iJc53hQEX9RKKpJLbTW/8A5Ly+u3zJu7JdF/m5fg2Z/hPTbvRfC2m2d/e/2lfWlpFDc3flCL7VIqAPJsHC7iCdo4GcV4f+3D/yUb9nf/spM3/qL+IK+gK+f/24f+Sjfs7/APZSZv8A1F/EFOcnJuTJjFRiorodpRRRSKCiiigAooooAR8lDtwGxwSMgGvkKT4MfFvw58cofi7qfhnwPB4g8I6Bq0OsHwzqF2H+I5MY+w27W/2d3hWPywfmM7q52oGBJr6+oqbO/MnZ2fyumr/j6PqmUmtmrrT8Hf8ArqulmePftJx/Fzx78BNNg+GkOi+HPFWt/Z/7UbU9QaGXSLZ03TrbyCCVTcg/IrvGVXJbaSAtfPHiX/gm9qFzdeAtXi+Ffw01aHwnpGr6Hc+FtZ8RS6jb3TXjRyrqbXktjukuTMJTJvi3YkLK+7C190UU5Ri3Jpb/AIXVrfc39997MUZSSS7fjre/32+6210eKfsd6D4u+DnhPSPhb4jsp9Uh8D+GNNT/AISs3MrxatdP5qy26LJEpxCI0wwdyVdNwQ8H518I/wDBLzxR4M8b28Wl6R8OtPGm+KNc19vGDvLLqPiCzvorlYtLvLdIo2eHdOglX7RtKQjZhm+X71op1P3k3Ulu7/i0/wA0vVaO+ooe7Hkjtp+C5f1fo3payt8Z/Db4A+Ov2avGF18StO+F3gLQ7nSfCdr4X/4RHwVezJB4lumvYi94xW1/dLEm/wArervh38yRFG+vWf2zfgRrvxbv/BWreHtG03VL/wAL3lzKZP8AhILzw/qdsk0BjP2W8tw21WOBLHIjB05BDKufc6KJ+/FRfS/4u7/Fv77LZBD3W2uv+Sj+SR89fsL/AAq1/wDZQ8FeG/hBdaLHdabo+gzazeeIra6nktRqNxfyySWSCWIF1USMyyGQuVX50TcpbB+L/wCzj8Tfi/8AtFeFtcudO8CaWPBfiqPVNM8Yade3EOq/2Gqt5mlPbGNt7ylmSRvOERU7goYBK+o6Kbbc1Ue61/G6+7Rea0d7u6suWUekv1Vn97u/V6bK3K/BPxxrHxI+F+la3r/h2Xwnq18sjT6VJM8zWu2R1X5njif5lVXAaNGAcAqCDXh3g39nX4jfCX4I6voFlpXgHxbDr3jbWtX1nRdUnmWHU9IvrmeVYo5thWOceZGWWSN0YBlyMhq+m6KlpNt91b5XTt/5KvkXzO3L53+dmv8A25/M+II/2JPitpf7LTfDC+0L4Z+MfDWpwam9ppd7q15C3gu6muJHsBbXRhczW9rE4UYijkVk+QlcBfrz4QeFdU8C/Cjw1out6vL4g1nSNLtrO+1OQHfqE8cSpJMc85dgW555ro6KpOya72/C9vz33el27Ihq8lJ+f42v+W2y6bhRRRSGFFFFABRRRQBw37Jv/J0Px4/6/ND/APTctfQtfPX7Jv8AydD8eP8Ar80P/wBNy19C0AFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXDfHf9nfwz+0doek2PiVNYA0HUhq2nXOlaxd6Td2V0IJrfzEntZI5BmG4mQjdgiQ5FdzRQB4P/w7t8Df9DF8ZP8Aw6XiL/5No/4d2+Bv+hi+Mn/h0vEX/wAm17xRQB4P/wAO7fA3/QxfGT/w6XiL/wCTaP8Ah3b4G/6GL4yf+HS8Rf8AybXvFFAHg/8Aw7t8Df8AQxfGT/w6XiL/AOTaP+Hdvgb/AKGL4yf+HS8Rf/Jte8UUAeD/APDu3wN/0MXxk/8ADpeIv/k2j/h3b4G/6GL4yf8Ah0vEX/ybXvFFAHg//Du3wN/0MXxk/wDDpeIv/k2j/h3b4G/6GL4yf+HS8Rf/ACbXvFFAHg//AA7t8Df9DF8ZP/DpeIv/AJNo/wCHdvgb/oYvjJ/4dLxF/wDJte8UUAfOfjn/AIJ/eDNH8E6xd2/iX4yJPa2M00Tf8LR8RHayxsQcfbfUVy37Kv7EPhj4k/sv/DfxFrHir4yXer694W0zUb6f/hZ/iFPOnmtIpJH2reADLMTgAAZ4r6Z+Jn/JN/EH/YNuf/RTVxP7Dn/JlPwf/wCxI0X/ANIIaAOZ/wCHdvgb/oYvjJ/4dLxF/wDJtH/Du3wN/wBDF8ZP/DpeIv8A5Nr3iigDwf8A4d2+Bv8AoYvjJ/4dLxF/8m0f8O7fA3/QxfGT/wAOl4i/+Ta94ooA8H/4d2+Bv+hi+Mn/AIdLxF/8m0f8O7fA3/QxfGT/AMOl4i/+Ta94ooA8H/4d2+Bv+hi+Mn/h0vEX/wAm0f8ADu3wN/0MXxk/8Ol4i/8Ak2veKKAPB/8Ah3b4G/6GL4yf+HS8Rf8AybR/w7t8Df8AQxfGT/w6XiL/AOTa94ooA8H/AOHdvgb/AKGL4yf+HS8Rf/JtH/Du3wN/0MXxk/8ADpeIv/k2veKKAPP/AIE/szeFv2c11tvDo16a58RXEdzqN5rOu3usXVy0cYjjBmupZHCqgwFBAHPFegUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBh/Ez/km/iD/ALBtz/6KauJ/Yc/5Mp+D/wD2JGi/+kENdh8W9Rt9K+FviKe6nhtoE024DSSuEVcxsBknjkkD8a4n9g7UbfUv2JfhC9vPDOqeC9HjZo3DBWFjCCpx3B6igD1iiiigD5V/bguk8Uftc/AjwR4s1C6074YeJ21eS+iS9ks7bXNVhhiNjY3EiMu5CrXEixE4kaIAhtuK8Mn+Nvi39nH9qjxr8Pfg/rdg/gfU/Gvhfw5bvrAn1qx8LX9/BeNqFtajz1IKrDbS+Tv2RvKflG7FfoJ49+HXh/4q+GJ9E8UaFo3iTRrrHn2GqWUd5azY5G6ORWU49xWd4e+Bngnwj4a0vRtK8HeFtM0fQ7tb/TbC00mCG20+4XO2aGNUCxyDJwygEZPNKC5Wr7J3f95cybT+Ssv+3ezu6j5otLdqy8nZ2a+e/wD293Vvg5P+Ck3xt1zxxL4C02y0C61vw/J4r+3a3baZaRx6iukX62kTeTfalaxRJtYSTlJnYArtVQSw6H9sP9qfx18YP+CcC3s3gfWvCWu6tF4Yvj4itdQ07UPDhupdU04ssEtrfPPNEWkYAhQGVWG/kMfsLxd+zL8N/iBpP2DXvh94I1uxGoS6sLe/0K1uYvtkp3SXO10I85zy0mNxPU10mueCNF8T+Gxo+paRpeoaQvlEWNzaRy2w8pleL92wK/IyIy8fKVUjBAoppqEVPVrlbfdp3b02voreV+thya9rzw0V3ZeWll52tu+9uh8Tab+2z8W5v2pD8ELnXfBltqX/AAl91o//AAmMmhOkZtotFt9SSBbQ3Ow3LvOyBvM2+XE52Fuaq/sHftS+Pf2m/wBtzT9Q8Qa9pqacvgHUIpNO06CZNN1GW01+4sTe2yvOwXzvISQNhiEOzJAD19j+Mv2e/APxG07U7PxD4H8Ia7aa3dR3uowajo1tdR388aCNJpldCJJFRQoZskAAA4FW7L4NeENO1zRtTt/CnhuDUvDlq1jpN3HpkKz6XbsMNDA4XdFGQcFUIBHanT0lCUui1826bjfy1d7bPfcmraUHGGl7fhPmt81ZX3VrbM+N7z/goN8Xb/8AaL16303QNBTwb4f+JsPgCS2vptNslmgIjDzfaJ9SjuTeN5hlihSzZXjUKu5juHB2f/BUr4y+A/gZ4Y8ea9/wg3iAeOfh5rfiy10210W4so9GubG5tYYt8n2mRpYSlwXl4U/uztZRX37e/ATwNqXxMi8a3HgvwnP4ygj8qLXpNIt21ONMY2rclPNAxxgN0qfT/gz4P0m20+G18KeGraHSbObT7FItMgRbK2mx50EQC4SN9q7kXCtgZBxUU0401GWrtb/yRx/GVp+W1zTmj7Rya0utPSV/y93ztdnydrX7WHxN0P8AaQ8G/B9PiT8K9V1PxhO083iC20aQT6LCunNdLbPam58tpbhlLQv5n+qSTKEgMfBPiv8A8FC/ih+1H+yv8Y9LGseC/Bo8GfDzUdQvb2OwmZfFrDUdR04z2Lm5U28JWzVkI80iW4QZYABv0Ni/ZD+E8HgCbwmnww+HieFrm6+2zaMvhuzGnyz/APPZoPL8syf7RXPvVrxj+y/8NPiHp+k2niD4d+BtctdAiMGlw6hoNrcx6bGRtKQq8ZEakcYXAxRVhzxlHvf8YtL7n02la71CjP2bjJ7q34O7/wDAu+8dlofDHwR/ar+I+o/Gp/h54MuPB/hZdW1rXDfapd6Tc6nPMNO0TRLiNwjXSIJHe7ZXIwu1RhQ2WObZf8FYPix45/Z78TePbbUfh14RufAvhfw1qsukahpM0/8Awk0+qAea8LfakeKIMTHGAHPmIwZmHA/Q3S/gt4O0TWxqVl4T8NWmohpnF1BpcEc4aWOOOU7wu7LxwxI3PzLEgOQox4n8d/8Agl94A+P2vWrajc32neH7S2tLOLQLHTtMWzs4LeTzPLtJHtWuLNZCAJBbSxhwOxyTvKfNNN/3fwvd+j0VttNjGnFRp8vVX+d5Jpeu+v4mn+1H8efFvhj46fCb4d+F9R0Lwy/xFTVbi517VLE3q2wsreOVbeGLzY1Mshk3ZZjhIpMKTyvkH7C37cHxU/bH+Nul6fcX3gzRPD2i+GY9Y1hLTRZp5NfmOqajp++2la5AggcWSTLlZT8+NzDmvrv4kfCDwn8ZfDi6P4w8L+HvFekJIsy2Ws6dDf24dfuv5cqsu4ZODjPNWtA+HPh/wpqQvNL0LRtNuxZRaaJ7WyjhkFrEWMUG5VB8pCzFU+6u44AzWdP3ZXl3fz0lb7m1ps7XepT1p8vWy1+av96vruumh8W/Gf8A4KCfFzQP2j/iFpnhrQNC/wCEY+G/ifRPD8sWpTabZQ6il6lvJK8t3dalbywyMs5FuIraVGaPBLliF5/wV+2z8fPih4i8Fx2niT4eaTZ+PT4zaNT4Wnnk0mLQbryYtpN4BK83G/cAoH3QDX2/4g+A3gbxb8QtP8Xar4M8Kan4r0kBbHWrvSLebULIDJAinZDImCTjaw6mrOnfB7wlpD2TWnhbw5bHTRdC0MOmwobUXTbrny8L8vnNzJjG88tms+WXs1FP3rPXzcUk/wDwJc1ul7bGqlH2nM17t1p5K+n4rXrbU/NH4d/tzfEhIvid8cbLXfCdrPH4K8Da/qHhK4sprgatNdwFZIbVvPVoN5dljwshMhTdkDDdov8AwVR+M1tZ6h40Hg3RbnwsuteJdJj0W4n06ym26XFdtGsDtqX2ye732ymWH7EMpKSgAUM/2/H+yn8LovEOk6svw28ArqugLEml3o8PWguNNWJQsQhk8vdGEUALtI2gADFaNj8A/Aul/Em78ZW3grwlb+L79DFc67Fo9umpXKEbSr3ATzGGOMFulaVvelJ09E+a3W13dfhp5boypWjFKer0v52Vn+Ot+uzPzn8TfthfEv4bftK6P4luPGPgnxFqfjj4ceGY7a9ttOkg0nw2ura5FE1zPB9qbzUjEh2P5iFsqGOASce5/aa8Z/s/fHD4q6jdX3hrxn4i0Lxd4subfUnt7iK2gksPB1tcxrHAlyVTLoFlQlhu8zbsJ4/R3Qf2TfhX4VttXh0v4afD/TYfEEL2+qJa+HbSFdSidtzxzhYwJVZgCQ2QSM07Qv2VPhf4X0Yadpnw38Badp4EwFra+H7SGECaHyJvkWML88IEbcfMg2nI4pSv7OcIaNqaXlzTU0v+3bPXeV9dkONudOeqvFvz5YODf/b29tlbTdnxnr3/AAUI+Mfw88daL4N1fVfA13e+NrTwjdQeIF0GW1tPDH9szXcc/mQm6bzkQ2yrEWkQ75l3buh+lf2Dvjv4l+OPhj4hR+KdV8Oa7e+CfHGoeFoNS0Sza0t72G2jt2V2jaWXEm6Vw2G25XAHFdR8bv2UvDPxp8GXOlCNPDc11Fa2st9pen2TTT2ls5eOylSeGWKa1+ZgYJEZMMcAHml/ZV/ZX8O/si/Dy+8PeHJLq4i1XVrjWr2eeK3gM1zNtDFYreOKGJAqIipHGqhUHBOSdFJc021p71vnKLj/AOAxUlfdt69yWnaNv7t/lFqT/wC3pWdtlbQ9MoooqBhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUV4H+3brmvQ3Hwh0DRPEut+FY/GXjhtK1K80iSOO7e2TQ9XvBGrujhczWkJJ25wpHegD3yivl//AIZu13/otXxn/wDBvaf/ACLR/wAM3a7/ANFq+M//AIN7T/5FoA+oKK+X/wDhm7Xf+i1fGf8A8G9p/wDItH/DN2u/9Fq+M/8A4N7T/wCRaAPqCivl/wD4Zu13/otXxn/8G9p/8i0f8M3a7/0Wr4z/APg3tP8A5FoA+oKK+X/+Gbtd/wCi1fGf/wAG9p/8i0f8M3a7/wBFq+M//g3tP/kWgD6gor5f/wCGbtd/6LV8Z/8Awb2n/wAi0f8ADN2u/wDRavjP/wCDe0/+RaAPqCivl/8A4Zu13/otXxn/APBvaf8AyLR/wzdrv/RavjP/AODe0/8AkWgDtf8Ago7+z2P2qv2Efit4BW3Fzea/4cuhp8ZGc30S+faHoelxFEfXjiuC/wCCKX7Of/DMH/BMX4TeH5oPI1PUtIXxBqIIw/n3zG6Kv/tIkqR/9sxVj/hm7Xf+i1fGf/wb2n/yLTIP2Z9ZtYEjj+M/xkjjjUKiLqtmFUDgAD7LwKAPqOivl/8A4Zu13/otXxn/APBvaf8AyLR/wzdrv/RavjP/AODe0/8AkWgD6gor5f8A+Gbtd/6LV8Z//Bvaf/ItH/DN2u/9Fq+M/wD4N7T/AORaAPqCivl//hm7Xf8AotXxn/8ABvaf/ItH/DN2u/8ARavjP/4N7T/5FoA+oKK+X/8Ahm7Xf+i1fGf/AMG9p/8AItH/AAzdrv8A0Wr4z/8Ag3tP/kWgD6gor5f/AOGbtd/6LV8Z/wDwb2n/AMi0f8M3a7/0Wr4z/wDg3tP/AJFoA+oKK+X/APhm7Xf+i1fGf/wb2n/yLR/wzdrv/RavjP8A+De0/wDkWgD6gor55/Yq1TxBpvxS+LXhTV/FviLxbYeGr7TW06fWpIZbqAXFkski7440yu4ZAI45x1NfQ1ABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAV8//tw/8lG/Z3/7KTN/6i/iCvoCvn/9uH/ko37O/wD2Umb/ANRfxBQB2lFFFABRRRQB4T+2t4R0/wCIniv4H+HdZgN7omt+PpIL+zMjJHeRp4e1qZUfaRuUSxRvg8bkU9q0v+HfPwZ/6EDRv++pf/i6P2ov+Sv/ALPf/ZQ5/wD1Gderwz9v608J6/8AtOzWfxObTT4SsfhVrGpaCuqyKlrHqqToJZ4txA+1Rw+UUZf3iBmKkZNZVKvJ+P8A5LFy/wDbbLzNKcOZ29Pxko/rd+R2H7Q37KXw9+CkHgPX/Cnhm00LWIvHvh23W6tZZVcRy6lBHIn3sFWRmUg9QTXW/td+B9L+KPxl+C3hvXrX+0dC1LW9Se7sXkdYbkx6TdPHvCkbtrAEZ6GuM1C+1/U/2Ff2fbjxUbhvEk+ueCJNSNxnzmnN7Zly+ed+fve+a9J+Pv8Ayc38CP8AsM6t/wCme7rpr0/Z1JU97O33MwpVPaU4z7q4f8O+fgz/ANCBo3/fUv8A8XXB/GD9mPwJ8B/iF8I9Z8H+HbXw/qk/jm1spLi0lkV5IJLS83xn5iCrYGR3xXj/APwUVj8Pan8b/jAfHL2Yl0D4Rx6j8P2vJArWmp/aLsST2WTkXfnrYruj+fBRc4bB96+L0+qXPgP9neTXAw1uTxZo7agGHzC4OnXRlz7791Z0/ehz/wBbyX/tuva6NKi5JqP9fDB/+3/gxfjf8KtA+N37bHhLQfFWnJrWjW/gjVr+OynkcQrcLf6dGJdqkDcEd1z6Ma6H/h3z8Gf+hA0b/vqX/wCLo1z/AJSC+GP+yeax/wCnLS6+RP2wnsZvi18d9U1B7b/hbGgeIfCUHw6eWQDULW3lNrsWxH3wks7XYlCDa+HD5C4CTvUUO/8Amlp3eu3ZMLe65dv617LzPoqX9n/wd8A/2xPhSfB2h2+gf2xZ65FfC2kkxdKkEDIHBYggMcj3qfxn8FPC/wAev27/ABRYeMNJi16x0bwFoVxY29zJJ5drJNqGtLK6qGADOIYgT3Ea+grqfjBn/hr/AOC27Gfs2v5x6/Zrel8Lf8pBfHf/AGTzw5/6ctepiWwf8O+fgz/0IGjf99S//F1yvgD4KeF/gR+3fpFh4R0mLQrHVvAWp3F5b28knl3EkeoacsbsrMRuUSOAfRj6182+Lnsm+OGt6yHtf+F3wfHyw0mwkkkH9qLoZSAi3QcyfYjYmZ2XHlk72+8M19ea5/ykF8Mf9k81j/05aXRD3qMave34xhL8p29Uwl7tR0+36SlH/wBtuvJnGad+z34O+Pv7XHxel8Y6HB4gfR20e2sftUshW0jay8xlQBgFBdixwOSa7P8A4d8/Bn/oQNG/76l/+Lo+B/8Aydd8cP8Ar40T/wBN618g/A97RfjT8LtYsmtv+Fzar8XPE1h4xkDA6nNpcf2/dDcAZf7LHCtiY1f5EzFtxuySHvVFDv8A5pfdrq+iHLSm59v/AJGUvv8Adsu7Z9Pfs+/CzQPgp+2t8SNA8LadHo2iv4I8M6gbOGRzD9oe/wBfjeXDE4ZkijUnuEX0rF+GH7NPgb49fGP41ap4x8PW3iC/sfG4sLaa7lkYwW66PpbrEoDABQ8kjYHdz613Xg7/AJSC/EX/ALJ54W/9OXiOj9lT/konx1/7KEf/AEyaRQIP+HfPwZ/6EDRv++pf/i6x/wBk3wBpHwp+PXxl8O+HrNdM0OxvNJlt7KN2MULSWCs5UMTgseTXKfs4eBpPAn/BS741Rza5ruvzal4V0HUJJ9UnWRoTJdaniGJUVUjhRVVVRV7ZJZmZj6H8D/8Ak6744f8AXxon/pvWj7Kl3/za/QJaTlDtb8Un+p7JRRRQAUUUUAcN+yb/AMnQ/Hj/AK/ND/8ATctfQtfPX7Jv/J0Px4/6/ND/APTctfQtABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUV4J/wAFLfj/AOOf2Vv2RPEHxF8A2GkarqPhCW3v9RstQt5JVuNOEqrc7NjoVdY2LhiSAEOQamU1FXlt+Xm/JbvyKhBzfLHf+tPn0Pe6K/PzVP8Agt1pemftPa7FFaHW/hTp+naJpulLo9gJ9Z8QeINUi+1RW8Mkk8dusUdsGL7yu1gMuMgH0a2/4LS/DDxJoXht/C3hn4meN/EHiGLUZ38M6DosVzrGkJYPsumuYmnVF2twBHI5ckbA2RVevn66f8C0r7crT2aJ328vx/q3qmt0z69or4Og/wCC3Ol+GPj78XNO8ZeCfFPhvwF8OtJ0e6tLqbSnTWLq6vkDxwTWzyK8ckpkRIovLyNjtIyDher8U/8ABbL4a+B/DmovrPgz4r6Z4p0nxDp/hq78Hz6LbjXo7m/gkmtGEQuTE0cqxMFKyk5KggZoWqTXX9XZfO7Wm+q7jcWnb+tua/pbqfY1fP8A+3D/AMlG/Z3/AOykzf8AqL+IK9m+HHjF/iF4C0fXZNG1rw8+r2kd2dM1iBYL+x3qG8qeNWdUkXOGUMcHjNeM/tw/8lG/Z3/7KTN/6i/iCiSadmSndXR2lFFFAwooooA8b/ai/wCSv/s9/wDZQ5//AFGderT/AGjPj58MfhDLpdp8QJoJZZkl1O1tv7EuNXkt4rfaZbxo4IZWhii3LuncKi7hlhWZ+1F/yV/9nv8A7KHP/wCozr1ef/tYeC/Ffhn9o688Z6T4P1nxlpmv/DfUPB8cOlrE81nftcCWEOHddkUoYqZOVUxjdgYNZVJyj8Kvv+EW198kkvNmkIp/F5fi0n9ybfyO3/a/1e18QfDL4fX9jcRXdle+PfCtxbzxMGjmjfVLZlZSOCCCCD71Z+Pv/JzfwI/7DOrf+me7rz7xR8ML/wCCf7FnwH8IarKs2p+GfEXgrTbt1bcpliv7RH2nuAwIHsBXoPx9/wCTm/gR/wBhnVv/AEz3ddNeMY1JRg7pPR/MwpSlKnGUlZtFz4//ALRvwr+EXifTLLx5d2o1K1h/teDdotxqX9kwhxF9sleKGRbSLeQvnSmNM5+bg4oftZzpc6r8G5I2WSOT4g2DKynIYG0vCCDXj/7ZPwm8aJ8WPi5daJ4O1fxba/Fv4Zx+D9LmsPKK6fqCPeJtuC7r5UJW7WTzMFf3TDO7aG9E+MvhSfwH4K/Z60O5m+03OjeLtHsZZs5814tPukZvxKk/jWdPWnd/1rJbeSUXfrzI0qWjNKOv/DRf5ykv+3Wb+uf8pBfDH/ZPNY/9OWl103xC+J3w88HfF/wZoviG70SLxv4llmt/DkEtuJr+UpG0kpjIUtGgRGy5KrnC5yQDzOuf8pBfDH/ZPNY/9OWl1iftL/AOTxV+058EvGGieGrWe90bxNLNr2rRQRrcRWS6XfxRCSQ4doxLOAq5ODISByTRH44p7XQvsSfVJteqVzb+Mf8AyeD8F/8Ar31//wBJrejwt/ykF8d/9k88Of8Apy16j4x/8ng/Bf8A699f/wDSa3o8Lf8AKQXx3/2Tzw5/6cteoA6fWPiZ8PNJ/aE0fwtdXeif8LJ1fTZ7mxtxbiTUPscWDIxcKTHHk8b2UMQduSpxzGuf8pBfDH/ZPNY/9OWl1j/Eb4CyH9vn4X+OdF8NWsdtDpmvJ4j1e3gjjkklkgsYrXz34eQ7YWVc52hMcCtjXP8AlIL4Y/7J5rH/AKctLpR1gm99f/Sn/XnuN76f1oHwP/5Ou+OH/Xxon/pvWrXhX9pT4T+Ifjzc+H9LvbJvGtxNPpT3Y0aeJL6a1XdNaR35iEE8sI5aJJWZMHKjBxV+B/8Aydd8cP8Ar40T/wBN618+fCr9njx3Z+Mfhn4IvPCurWMfw6+JuueMb/xE5iGn31hO1/JbmOQOWkllN4iMm0MnlvuwNpZw1qKL2/4KTfyTbtu7aBLSm5df+BJr72kr9Ln0H4O/5SC/EX/snnhb/wBOXiOj9lU/8XD+Ov8A2UI/+mTSKPB3/KQX4i/9k88Lf+nLxHUP7M1qb7xn8fYVcxtN4+dA46oToekDIqZtqLcVdgrN2Zs/C79q74afFz4k3OieG9Zju9eeGZlkbS7m2j1OK2l8qVra5kiWK7SKRtrGF5ApbnGazPgf/wAnXfHD/r40T/03rXgv7JHwG8c6V4z+AGh6x4S1bw9F8C9I1uy1rU7gxLZ6nLOq29uLVldjMJVBnZsALgBsMdte9fA//k6744f9fGif+m9atpJK2u/z1avbpddGJ/E1/X/B9T2SiiikAUUUUAcN+yb/AMnQ/Hj/AK/ND/8ATctfQtfPX7Jv/J0Px4/6/ND/APTctfQtABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRXhf/AAUj/a6vP2Gv2OfFnxJ03R4dc1LRhbwWdrcMy25mnnjgV5SvzeWpk3EDBOMZGciZSUVd/wBX0X4l04OcuWJ7pWT478F6d8SfBGseHtXgF1pWu2U2n3kJ6SwyoY3X8VY1+clz/wAFb/jrav4f8LP4U+Hdv4w1v4i6b4Mi1W70++g0ya3vrWSVZvsZuTcwyRPHhldyHUgrjOQvgP8A4K8/GX4paz4U8A2Ol/CPw/8AEDUdd8VaZqWua0l8vh0R6IoJ8qITiVXk3clpWCKu7DZwCcIyThJXTT+a5Yyf3Rmr/gTCbi1OLtt8neSX3uLt+J6n4V/4IN/CTwJ+zTpnw80jV/FcFxonipfGNh4huDZ3V/HfLGsSrJG8Bt5YPLUKYniII69a2Z/+COHhrSrbwxfeGviV8SfCXjLw/Y3+lz+J9NlsUvtTtL1t08Tp9m8mPb/yyaJEaPgglgGrxb4pf8Fi/inpj+PLjwvafA6+034N+EdK8SeJbldVu9RtfFT3ZTcmj3MbRqIlDFRJIkn7zCY715N+2x/wVA+LH7Rnwn8Xah4XutC+HHgvwn478O6B9miu7y18XXMlwEnZvNjlWMQt8ymPy8squd3ykG4/vKij1bSfkm1ST9H8NuqWqsTJ+zp872SbX/gPtLeqvzeTemp9d+P/APgil4D+JHiHxZdal44+JU9t400XStN1RZtRgubue70wItnqRu5YWmNyuzJyxRy7blIwov6d/wAEd/B954tTxX4m8cePPFvjqXxlo3jO/wDEF9JZxT302lRyR2dqY4rdYktwkh3BFDsed4wAPmX4I/8ABRj4tWXxI0zwD4ItvCT6n8Qfiz400H7b4ruNV1aOxj02O2ljZAbveqkO/wC6RljHyhQgyal8If8ABb/4ufFrwD4em0XQ/hR4Z1mD4cax4+12fxALxrHUDYahcWYtLELOjIz/AGcvl2kxuxj5cmIVeWnGvHayl6ae0v8ALk+fKl2RrKlJt03/AIPX3nTSfq07dFv5n6o18/8A7cP/ACUb9nf/ALKTN/6i/iCu0/Yy+NOpftHfsn/Dvx7rFtZWeqeL9AtNWuoLNWW3hkmjDsqBmZtoJ4yxPvXF/tw/8lG/Z3/7KTN/6i/iCtatOVObpy3Tt9xjCanFTjsztKKKKgoKKKKAPG/2ov8Akr/7Pf8A2UOf/wBRnXqq/tGftZ6v8JviKvhTwp4Nh8Y63a+G7vxbqaXOs/2XFaafA6x4R/Jm8yeRywRCEX5G3SLVr9qL/kr/AOz3/wBlDn/9RnXqy/2kf2XfFPj/AOKjeMfBHiDRdH1bUfCd54N1KLVrOW4hNrPIsqXEflup82Jt5CN8rh8ErjJyqc/2PP7+V8v/AJNy38jSny/a8vu5lf8A8lvbzsUfj58TNO+M/wCzv8JfF2kGQ6X4m8Y+EdTtfMGHEc2pWsihh2YBsEeoNdF8ff8Ak5v4Ef8AYZ1b/wBM93XL/Gv4V2PwN/Zo+D/gzTXeWw8LeLvB+lQSOAHlSHUbWMM2OMnbk+5rqPj7/wAnN/Aj/sM6t/6Z7uumvye0l7P4b6el9DClz+zjz7219TC/aT/bb1D4K+OPEmkaD4Lj8WR+A/C6+MPFE8usf2ebGxaSVVS3XyZBPOVgnfYzRLiMfPlgKvftI+JLXxlZ/A3V7FzJZar450y8t3Ixujksrt1OPoRWJ+05+xj4l+K/j/xhq3hTxJo+jQfErwgvgrxFHqFlJcPBbrJOVurba6gyiO5nTY428q275Sra/wC0P4VtfAulfAnRLEEWWj+NtLsbcN1EcVjdoufwUVnT+D3t/wDgy/C3Jb53120qW51ybf8AAj/7dz3+Rp65/wApBfDH/ZPNY/8ATlpdcp8Y/wBv2b4W+PvF8Nt4OXVvBvw4vtK07xVrbav9nuLKa/8ALK/Z7XyWFwsSTQtIWljID4UOQa6vXP8AlIL4Y/7J5rH/AKctLrhPjZ+wXrnxL8b+Pbew8R6TZeB/ivqWkan4ktbiykkv7d7HyQ6WzB/LxcR28KkuuY8MRvyAqjf2ivt/wVv5Wvtrewacr7/1t5+uh3fxiO79sD4LEf8APtr/AP6TW9Hhb/lIL47/AOyeeHP/AE5a9R8Yl2/tgfBYDgC218D/AMBrejwt/wApBfHf/ZPPDn/py16mJbanJ6x+3/NpXxNu4P8AhDlfwBp/jaD4f3PiI6vtuk1SUINy2fkkNbLNIkTSeeG3Eny9ozXWa5/ykF8Mf9k81j/05aXXB61+wTreq/EW9tf+Ej0j/hXOp/EGD4j3Fm9lI2preRCNzaK+/wAvyWuIllL7dwG5NpzuHea5/wApBfDH/ZPNY/8ATlpdEP4Mef4tL/8AgMb/APk/P8rerJ/xXb4en/gUrf8AkvLfzuHwP/5Ou+OH/Xxon/pvWuT8Df8ABQGXxd8SfD8E3g9bLwJ4w8Uaj4P0LxANX8y6ur6y84M0tn5IEcEj206xuszsdg3Im6us+B//ACdd8cP+vjRP/TetcF4B/YG1rwr8QfCttd+JNKuvh94E8X6n410a0SzkGpPc3n2hlt5XLmMRQvdTMGUZf5AQu0liH8Rc23/BV/na9ul9xyt7N23/APtZW+XNy362O98Hf8pBfiL/ANk88Lf+nLxHTf2XJ1tfHvx4kkYKkfxBZmY9FA0PSCTTvB3/ACkF+Iv/AGTzwt/6cvEdM/ZetkvfHXx6hkG6OX4gMjD1B0PSAamfNyvk36ArX12OZ+AX7e9x8Y/HPgq11DwYNA8O/FGz1C/8H6mNX+1T38dmwLC6t/JQWzSRMJUCySgrkEq3FdT8D/8Ak6744f8AXxon/pvWuH/Z4/YS174U+Nvh0dc8SaRqvhr4O2GpWHhaK2spI7y5F4VVXumZ2UGGBfKAjGHLFjt4Su4+B/8Aydd8cP8Ar40T/wBN61btZW8/Xd2v0va22gvtP+vu8vU9kooopAFFFFAHDfsm/wDJ0Px4/wCvzQ//AE3LX0LXz1+yb/ydD8eP+vzQ/wD03LX0LQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVmeM/BWj/ABG8K3+heINK07W9F1SE295YX9ulxbXUZ6o8bgqwPoRWnXwX/wAFU/EHxA0/9ozwVbT6r8ZtB+DT+GtTlnvfhtDem+fxAARaRXL2aPMIyCuxWxGz/eyAcZVZqKs1e9/wTf42sl1bS6mtKDk9Ha3+aX4Xu+yTfQ9yh+GP7Mn7P3jLwf8ADldD+EfhfxFc6mmveHNBa2s4b6W+UNGl5BER5hlAVlWUDd8hAPGBf1L9nL9nb453Wv8AgGfwf8LvElz4Z1T+2dY0RbG1mm0u+vB5huJogN0cs4XJY4MgXnIr4k/4J1fAv4w+Iv8Ago78P/H/AMX7H4hWviA/BmOTVL+4a6gtGvRf+VFZ3BGIg5thHNJbHH73dIyb8mqH7Xtj8fLj9qj43W/hWT4w6Vomq/ELwNZ6de6Al9Co017W5XUGtpI12+UrFDIy5VWC7u1dMqb5owlrJt+mlWNNfkpeiXYyTXJOpHRRUX56x5n/AOlNfN92foR4x/YZ+DHxB1HQbrW/hV8PtUn8LwR2mktcaBbP9ggj/wBXDGNmBGmflT7q9gK4KfwB+yf+0j8aLXVZNJ+CfjXx5rnnR207QWF9qF81kQJSvBZ3gKqGYfMgUAkDivhnxHP8dvh34xHhnxL4g/aNHwT0T4xazY6jrOmy6td+If7IFpCdO2XUSveTWhmaUF0LKTgZzgV5D+zh4C/aU+E3w+8NL4A8MfFbStWTR/Hd3FHqWkXMEhupCDayTq6BPtTKWMQYfNJjaDXNGtf970UZT878kZ/Ju9u7aNKlJpKD3cow8rc8ofcuW/kmj9mNG/ZW+Gfh3xFZavYeAPB9nqum6jd6vaXkOkQJNbXl2qrdXCOFyssqqodxywUZJxXgn7WX/BIjwd+0XpuhaboN5ofgPQtC06702DSIPBmk6jZ2y3LtJJNbCeEvazl3Zi8TjJ2nG4Zr4z8ZePPitD+zlaD4Y6v+1/f6edY8Ojx9qPilL8NYwNA/29dNlMR1RSs4AuDbqyINvl8HnB+K/iP9pG0+B/gm6fxl8cZ7GOTXf7PhbTPEmmXOo2/mKbQSXtmj3jXg+Zbf7fb+TKpVnGM1dSEVeMtou34duqafu6a6vQVOUnZreWvpq3r2a15u1+tz9dvgL8G9L/Z4+CnhTwJosl3NpPhHSrfSbSW6cPPLHDGEDOQACxxk4AGTwBXln7cP/JRv2d/+ykzf+ov4gr0f9mXxDrPiv9nbwPqXiLStb0TXb3Q7Sa/sNZlWXULWYwrvS4dUjDS5zuPlpzn5VPA84/bh/wCSjfs7/wDZSZv/AFF/EFb4nm9rLnd3d39bnPQ5XTi4qysjtKKKKyNQooooA8b/AGov+Sv/ALPf/ZQ5/wD1GderA/4KM/Fr4jfBb4MWWu+ArnQtNt7fV9Ph1i+vFM12kM1/a24itoSjRln859zyH5FX5VZmDJv/ALUX/JX/ANnv/soc/wD6jOvV3vxh+EOifHXwFP4b8RQzXGlXNxbXUkcUzRMXt7iO4iO4c8SRIT6gY70vtRfZq/pdX/Aa8zgv22P+RJ8Ef9lD8Mf+na3o+Pv/ACc38CP+wzq3/pnu6P22P+RJ8Ef9lD8Mf+na3o+Pv/JzfwI/7DOrf+me7piPKv2vPj98QdO+KfxRsPCXix/Cdp8Ivh1H4zWCPT7S6Gv3bvdsIbgzxuy24jsypEJjfdNnfwBXcfGvxe3xB8Ifs+688Btm1vxhpGoNCc/ujLp91Jt5543Y/Cur+OX7Gvgr9oPxI+qa6mswXN5pn9iamNO1KW0TWtP8wy/Y7lUIEkW8sezYdxu2swOZ+1bZRabffBm3t40hgg8f2EccaDCxqLO8AAHYACinpC0t/wDgye/mnFW6cunm6lnNOO3/AAIr81J/9vfdLrn/ACkF8Mf9k81j/wBOWl14f+0X+1T8Q/C/i34yeKNE8TPpuhfBbWdC0yPw2mnWs0OvpdLbSXT3EjxtcKxW62xGGRApiyQ+SK9w1z/lIL4Y/wCyeax/6ctLq18Q/wBinwL8T/iTceJtUg1bztSnsbrVbCDUZYtO1qaxbfaSXMAO2QxMFx0DBFDhgoAUb+0Uun/BWtuul1Z6a+QacrX9f8D1Knxgbf8Atf8AwWPIzba+cH/r2t6Xwt/ykF8d/wDZPPDn/py16j4x/wDJ4PwX/wCvfX//AEmt6PC3/KQXx3/2Tzw5/wCnLXqYlsYHjn4tfEbw9/wUK+H/AITludCs/hz4l0jV5obW3UzX1/NaxWrGWd3QeUFecqiRE5ClnY7gib+uf8pBfDH/AGTzWP8A05aXXe+IvhDonin4o+GvGN5DM+ueEre9tdOlWZlSNLsRCYMvRsiFMZ6YOOtcFrn/ACkF8Mf9k81j/wBOWl0o6QSe+v5tr8LDeruHwP8A+Trvjh/18aJ/6b1rB8N/Fn4jH/gotfeC9dudDtvBE3g6fWNI06xUyzuyXsMIuLiZ0VhIwZwIk+RRjJduRvfA/wD5Ou+OH/Xxon/pvWu9l+EOiTfGSHx40M3/AAkcGjvoSS+afLFq0yzldnTO9Qc9e1OOlWMnsua/zi0vulZ/jvYmetNxW+n4STf3q/5bXOC8Hf8AKQX4i/8AZPPC3/py8R1D+zLeDT/Gnx8nKlhB4+eQqvU40PSDgVN4O/5SC/EX/snnhb/05eI6P2VRn4h/Hb/soR/9MmkVM1Jxai7MpWvqeKfsq/tP/ETxP41+B+r+I/E7a9pPx30vWL+XRhp1rFb+GpLdVnt1tpYo1lZRETG/nvIS2GBX7te1/A//AJOu+OH/AF8aJ/6b1q18Jf2KfAvwX8dW2vaNBqzTaVBd2ujWl3qMtxZ6BFdSiW5S0iYkRiR1XPUhQFUqvy1V+B//ACdd8cP+vjRP/TetW2rJLz/N2V+tl1YvtN/193T0PZKKKKQBRRRQBw37Jv8AydD8eP8Ar80P/wBNy19C189fsm/8nQ/Hj/r80P8A9Ny19C0AFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXz/wDtw/8AJRv2d/8AspM3/qL+IK+gK+f/ANuH/ko37O//AGUmb/1F/EFAHaUUUUAFFFFAHjf7UX/JX/2e/wDsoc//AKjOvV4Z+39aeE9f/adms/ic2mnwlY/CrWNS0FdVkVLWPVUnQSzxbiB9qjh8ooy/vEDMVIya9z/ai/5K/wDs9/8AZQ5//UZ16tP9oz4+fDH4Qy6XafECaCWWZJdTtbb+xLjV5LeK32mW8aOCGVoYoty7p3Cou4ZYVjVhzW1tv+MZR/C/MvNfM1pyaeivt+Ek/wAbWfkzyPUL7X9T/YV/Z9uPFRuG8ST654Ik1I3GfOac3tmXL5535+975r0n4+/8nN/Aj/sM6t/6Z7uq37X+r2viD4ZfD6/sbiK7sr3x74VuLeeJg0c0b6pbMrKRwQQQQferPx9/5Ob+BH/YZ1b/ANM93XXiJ89WU2rXb07anNRjy0oxTvZLU8+/4KZeBpNVj+E2vNrmuQwaV8RvDkKaTBOsdhcvJqcIM0yhd8jqowoL7FyTt3YI9B/a6/5Dfwe/7KHY/wDpJe1rfHL9qf4b/BHXLTSvGerC3uzANV8tdKub9bC3WQRi7uGhikW1hEhAE0xRMg/NwcY37Wc6XOq/BuSNlkjk+INgyspyGBtLwgg1lT0pcq25m7+qirfJx/ToaT/icz35Uvubd/8AyZfn1H65/wApBfDH/ZPNY/8ATlpdeefth+BpIv22f2cfEb65rsyS+KrjT4dJadV022H9kag7TLGqgtMxCgu7NtVcKFy270PXP+Ugvhj/ALJ5rH/py0utP4hftXfDPwF8UrTwtr+sxxa/BNbKCdLubi30yW7LR26z3SRNBavMcqglkQvnjOaIu1SLW91bz8gfwTT2cWvS6tf5GZ8Y/wDk8H4L/wDXvr//AKTW9Hhb/lIL47/7J54c/wDTlr1Hxj/5PB+C/wD176//AOk1vR4W/wCUgvjv/snnhz/05a9QB8h+Lnsm+OGt6yHtf+F3wfHyw0mwkkkH9qLoZSAi3QcyfYjYmZ2XHlk72+8M19ea5/ykF8Mf9k81j/05aXVq/wD2lPhPaftAp4dnvrL/AITiO4TRBd/2NO0cVzJH5y2J1AReQs7R/OIDKHIIO3mquuf8pBfDH/ZPNY/9OWl0qfu0IwWtra+kYR/Hl5vWXzZU1rOT69PWUn+F+VeUfkj4H/8AJ13xw/6+NE/9N618g/A97RfjT8LtYsmtv+Fzar8XPE1h4xkDA6nNpcf2/dDcAZf7LHCtiY1f5EzFtxuyfr74H/8AJ13xw/6+NE/9N61a8K/tKfCfxD8ebnw/pd7ZN41uJp9Ke7GjTxJfTWq7prSO/MQgnlhHLRJKzJg5UYOHDSqpdfx0cX9ztaXkxz1pOL2/zjJffrdeaKvg7/lIL8Rf+yeeFv8A05eI6h/ZmaZfGfx9NuAbgePnMQPQt/YekY/WpvB3/KQX4i/9k88Lf+nLxHR+yp/yUT46/wDZQj/6ZNIqZx5ouO1wTs7nyV+wadMg+LX7PN/4ektm8deJND8STfE+SKQNf3ksciAvqGMkvHenZGZeVyVXjIr61+B//J13xw/6+NE/9N6103gP4nfDzxB8aPF/hnw5d6JP410OK2uPEcVlbgTQiXeIRPKq7Wf5G+QsWUYJADDPM/A//k6744f9fGif+m9a0veK+fpq29PJbCfxy7/jt18/0seyUUUVIBRRRQBw37Jv/J0Px4/6/ND/APTctfQtfPX7Jv8AydD8eP8Ar80P/wBNy19C0AFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXz/+3D/yUb9nf/spM3/qL+IK+gK+f/24f+Sjfs7/APZSZv8A1F/EFAHaUUUUAFFFFAHjf7UX/JX/ANnv/soc/wD6jOvV5/8AtYeC/Ffhn9o688Z6T4P1nxlpmv8Aw31DwfHDpaxPNZ37XAlhDh3XZFKGKmTlVMY3YGDXov7WHhfxNqOq/C7xB4Y8Oz+Kp/BHi5tYvNOt7y3tZ5rd9H1OyzG07pGSJLyIkFh8obHIxUX/AA0J8Sf+iCeMv/Ch0P8A+TKznTU9/P8A8mi4v8JP5lwm47eX4NSX4pHn3ij4YX/wT/Ys+A/hDVZVm1Pwz4i8FabdurblMsV/aI+09wGBA9gK9B+Pv/JzfwI/7DOrf+me7rlfilq/xJ+Pc3hHR3+EWv8Ahm1sPFuj6zd6jf65pUsNvBaXsVxJ8kNy8jMVjIAVTyR0HNdX+0/4e8Ur8Qvhj4q8M+F7rxf/AMIjqt7NfWFrfW1pP5U+n3Furq1xJGhAeRcjdnB4BretUdSbqS3bv95jTgoQUF00PG/2yfhN40T4sfFy60Twdq/i21+Lfwzj8H6XNYeUV0/UEe8TbcF3XyoSt2snmYK/umGd20N6J8ZfCk/gPwV+z1odzN9pudG8XaPYyzZz5rxafdIzfiVJ/Gt//hoT4k/9EE8Zf+FDof8A8mVzPjbUfiL8dfHXw6t7n4T674U07w94qg1u91G/1rS54o4Yre4QgJBcPIWLSqBhT74qIe7HlX9aya/Gb/DsaTbnJSfT/KK/KC/E6bXP+Ugvhj/snmsf+nLS6+f/ANpX9n7x3rvir44+ENM8Kavqcfxm1zw7qOk69AYvsWnw262kd19pkZ90ZgFqzqu07/MUJk5A92+NWmeMvCH7Tvhrxv4d8E3/AI206DwvqOh3UFjqNnaT20s13ZTxuftMsaspWCQfKSQcZHNWv+GhPiT/ANEE8Zf+FDof/wAmUkrTUv6eqf5pBd2aE+MC7P2v/gsMk4ttfGT3/wBGt6Xwt/ykF8d/9k88Of8Apy16sXTX8e/F39pnwDrurfDXV/Bmi+E7XVftN1qGr6dc+c9zFEkaIltPI2coxJIAAHWp/Htv44+Gv7WmteMNC+H+p+N9G1/wjpWjbtP1WxtJLS4tLzUpnDrczR5DJeR4K55Vs44yxLTQ8R8Tfs+eOr3xprPgRPCurmLV/jTafEKLxLGYv7PTSkeC5ctIX3CdWiMAi27jlWHyZYfQOuf8pBfDH/ZPNY/9OWl0f8NCfEn/AKIJ4y/8KHQ//kys34dW/jf4iftZWPjDXfh/qfgnR9I8JX2jBr/VLC7e6nnvLKZQq200hAC275LY6jGaIe7SVJbK34RjH8or539ESV5up3/WUpP8ZP5WNL4H/wDJ13xw/wCvjRP/AE3rXz58Kv2ePHdn4x+Gfgi88K6tYx/Dr4m654xv/ETmIaffWE7X8luY5A5aSWU3iIybQyeW+7A2lvabp/Hvwd/aN+Ies6X8NdX8aaP4w/s2e1utO1fTrbyTBa+S6OlzPG27cMggEYI5zkDa/wCGhPiT/wBEE8Zf+FDof/yZRHSan2/NNNP5Neg3rBw7/qnF/hJh4O/5SC/EX/snnhb/ANOXiOj9lT/konx1/wCyhH/0yaRVb4EaV4w8TftM+OPHHiTwXf8Agqw1PwxoehWVvfajZ3c9xLaXWrzzP/o0siqu29hA3EEndxxWL4XvviJ8Dfip8UPsfwq1vxdpfivxQNcsNQ0/WtMgjaI6bYWxRkuLiORWEltJn5cYwQTmgRY+C3wDk+GH7dPxL17TPDVrofhTXfDOjw289pBHBBd3q3Woy3R2rgmTM6MzEfMZM5JzW38D/wDk6744f9fGif8ApvWj/hoT4k/9EE8Zf+FDof8A8mUn7M2g+K7n4p/EzxZ4m8KXfg9PFN1p/wBhsbu/tbudkt7RYndjbySIAWzgbs8dKL6KPb/O/wCoPWTn3t+CS/Q9looooAKKKKAOG/ZN/wCTofjx/wBfmh/+m5a+ha+ev2Tf+Tofjx/1+aH/AOm5a+haACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAryD9rr4H+KPjFB4Av/B99oNlrfgPxOfEEaazHK1rdq2mahYNGTF86nF9vB/6Z475r1+igD5w/4V7+0T/z8fBb8tTo/wCFe/tE/wDPx8Fvy1Ovo+igD5w/4V7+0T/z8fBb8tTo/wCFe/tE/wDPx8Fvy1Ovo+igD5w/4V7+0T/z8fBb8tTo/wCFe/tE/wDPx8Fvy1Ovo+igD5w/4V7+0T/z8fBb8tTo/wCFe/tE/wDPx8Fvy1Ovo+igD5w/4V7+0T/z8fBb8tTo/wCFe/tE/wDPx8Fvy1Ovo+igD5w/4V7+0T/z8fBb8tTo/wCFe/tE/wDPx8Fvy1Ovo+igD5w/4V7+0T/z8fBb8tTo/wCFe/tE/wDPx8Fvy1Ovo+igD5w/4V7+0T/z8fBb8tTo/wCFe/tE/wDPx8Fvy1Ovo+igD5w/4V7+0T/z8fBb8tTo/wCFe/tE/wDPx8Fvy1Ovo+igD5w/4V7+0T/z8fBb8tTo/wCFe/tE/wDPx8Fvy1Ovo+igD5w/4V7+0T/z8fBb8tTo/wCFe/tE/wDPx8Fvy1Ovo+igD5w/4V7+0T/z8fBb8tTo/wCFe/tE/wDPx8Fvy1Ovo+igD5w/4V7+0T/z8fBb8tTo/wCFe/tE/wDPx8Fvy1Ovo+igDxf9lL4FeMPhj4t8f+JPG2oeGrrV/Gt5ZyrBocU621rFbWywrlpjuZmOSeABx1zx7RRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUjnapPtSbsrsBaK/Pj4Sf8FJ/jB8WfCOs67Drv7OWn/2O9+x8PXc96mv3UVpG8jNFbi4O7KISDwDtboBmvSfCP8AwVf0mD4KWOrax4c1rXPE9t4Tj8U65BoVvDBZadDI+xCTc3AbBYpxH5rDd0PSi65Od7aP5NN/lF/cNxanyddV9zS/NpH19RXy3F/wVV8JaJ4F8R6p4g8OeIbS88IabpOp6pb6aYbyFk1JUa3EEsjQtIQsiF98ceDkDdjm/wCJv+Cp/wAOvB3jjxlomo6X41t/+EFGNU1AaWklkrsE8qNXSQnfKz7UVlGSrZwBmqaa/rt/w4lqk++3zPpWivMv2ff2qvD/AO0RqWv6bYWOt6Fr3hh4RqWkaxBHFd2yTJ5kMn7uSRGV1zja5IxggGvTFbcoOMZHQ9qT0aT66iTT2FooooGFFFFABRXxr+0v+3Z8QPh/+2NqXw38P618E/CulWGiQaqupeO7i5tEmdyA0SypMqluchdvRW54ro9K/wCCovhfwZf694f8b2eqnXvA2nx3PiTWND04zeHxI8SPH9nlMrSbZWdUiEigsx9OaItOPMvP8G0/yG01Ll9PxV199z6nor5o1r/gqh4A8MeHNTu9V0Hx1pmp6ReWFrc6LPp8H9oqt6pe3nVFnKPGwHO1ywJAK5OKq6P/AMFYPAeo+KrTSbrwp8SdHml8Qr4WvJr7R4kg0q/ckJFO6zMAWwxATecKSQKai3LlW/8Aw3+a+bsTzJLm/rr+ib9D6horyb9qv9sXw7+yJY+HZtf0rxNrD+KL5tOsLfRLNLqeScLuC7GkQktwqhckkjgda4zVP+Cl3hLRfF1ppl34Q+JVpb3+rLoMGpXGjJDZy6gybltQXlEhc/dyE2Z/ixzU3T/L8v8ANfeimrb+v5/5P7mfRlFfLujf8FdfhRq6aFmPxJaNrujahrapcW0CtZx2X2jzIpgJjtmb7NJsUbgflyRmuu/ai/a5vfhB+xZcfFLw/wCHtRubu6063vLK0vbUP9i89QyNdokq7UUEBtjkgkAZom+WLm9l/wAFfo/uCK5pqC3f/A/zR7pRXzFaf8FOvDeg+B/D0uu+GPG3/CR3nh7/AISLVtMtdOhEulWafK93IHnAELkM8YVnkKEHbzWz49/4KT+BfAXi3QtIbSfGGqyeLtMttU8NT6dYRSweI1neNFitiZVIlXzMssojChSSembcWpcnW9vnr/k/ufZkKScebpa/y0/zX3p7M+hKK+a/2fv23td+MH7Z3xF+HV54O1nT9F8L/Z47K7awVHtG8p2kN4/nsoErLmHYvK/ewar+MP29dR8G/t7SfDO68L6ovhKx8OnU7zU1sQZIH8wE3hk87aLFI8qzeXvEgPBHNQmny/3ldelm/wBCmmuZfy2T+dv8z6corwz4Ff8ABQLwV8fPHel6Bp9h4n0ifxHYzaloNxq1kkFvr1vC7JJJblZHbgqx2yKjYGcVL8Wf29vB3wW+IHivw1ren+I01Pwro9vreIreFl1aGeaOBEtcygvJ5sioQ4QZzzjmm000n1vb5Xv89Hp5Bve3S342t+a+89uor5/b/gpJ8Po/iOdAe38Rx2kWtx+GrjXGtYv7LtdTdci0d/N8zcD8pcRmMH+PBBrM0H/gqH4G8W61cWuk+HfiDqFq5vYtK1OHRlNhr89ou6WG1kMgLP8A3fMCAnAzkik5JR5vK/5P9VbvdW3Dd2/rr/k/SzvsfSdFfH/7Nn/BUpfGn7Pvh3xB408K68vijxNrEmkaTYaLpyiPXpfNkA+x+bcEFY1VVkaV0Ac8ZyK6XVP+Crvw5s9O8Jy2mj+OdYufF9zd2MFhp+lJLeWd1asizQTRGUEON6n5NwxznFU42lyvf/gX/Vfeu4dG/X8G1+j+59j6borxH9nL9vPwl+1F4rbTvDOkeK/spjnlg1S4s4jY3Ahk2MC0crvCSTlROkZYdAa9uos0k31Dq12CiiikAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABSMNyketLRQ1dWYHzP8Df+CZ/hj4O/AvxH4YnfQda8Sa5/aSw+KJPD0Ud9YLeRNHtUl2chAzdJF3AkcZr5y8W/wDBPH4tfDP4i2kGhaXYeO9F8PeHbHSNJvNS0LRtVt3eEMzkQX93E9iDIxz5RlLZLZzhR+ktFK1mmulvwTS+5N/frcd73v1v+LTf4pfofD/jv/glt40/aBtNd1nxH8RNO8Jax8QdL0yHxNpOmaAt5Zrc2QQR+TI0yMqAIMquPmz8xXAru/Fn/BMDSvHuh/F6w1bxRPLF8UdRstUgeHTxG+izWqkJ96RhMCTyCE4yO+R9S0U3a3KtF+WqenzSt2sJXvFvVr/K35Hin7In7HkX7L82vXk2o+H9T1PXjCrvo/hWz0C2gjiUgKscGWYkksS7kZPAXnPs9sjxW0ayP5siqA7hdu845OO1SUU5Nyab6CilFWQUUUUhhRRRQB4Rr37B3h3xt+19qvxR8SjRfE1lqOhRaPHoOp6JFdRWzoysLgSSMw3YBGPLBG4/NXPeJ/8AgmtovjT/AIXTb6jrrjTfi6bB4be109YG0FrNMRFG3kSDcFONqDAK9819MUUrLl5emq+9835633XQd3e/mn80rL8Omz6nxxr/APwScn8cW+p6h4g+I7an4t1W+0iaTVE0BYII7XTl2xwLbifhnwpaQueVGFra8Sf8Exf+Eh1fXLr/AITfyv7a+JFt8Qdv9jbvJ8kSD7JnzxnPmf63jGPuHNfVtFUpNSUlutfxi/zhF/Lzd55Va3y+Vmvyk1/wyPKP2jP2Yv8Ahf8A46+Gmtf23/ZP/Cu/EKa75P2Pz/7Q2gDyt29fL6few30rw7Uf+CTU+sfGK38W3vxGOpXNp4yh8WRTX2gLPqJSNw32Froz58kYAUKiqvUq3yhfsiilD3JKcd07/P3f/kV93mxy96LjLZq3y1/+Sf3+h8QeLv8Agid4d8TX/iKaPxfNZDXPFSa9EiaXu+w2X7/zdPU+cMq/nt8/GMDKGvqL9or4DWf7QP7P3iHwA94+j2muWIskuIYhJ9l2lWQhMgEAqOMjI7jrXe0VPKnT9j9n/gKP5Jfnu2VzP2ntftf8G/5/5bJHxt4v/wCCTlx40udD1W/8eaLqHiaw0EeHL+91LwRaX9td2yMfIkitpZGWC4jj2p5oZs7c7eSDsfFT/gl83xH1jSdSt/iDd6LqPgq00618GSWmjxxReHvszB5pGhjkjjmadhk7REFAUAECvrGir5nfm63v89Xf8X95Fla3lb5aafgvuPEfht+yXq3w1/av8U/Eq18ZpJY+N7a1TWtEOjqBPPbweUkkc5lLRrks2zaeuCxxmqfxe/Ymk+Jn7TsHxDtvFjaXbXnh1/Cuu6Q+lrcrqtg7szokpkUwscgbgrEY47171RUtJpJ9NF6Wat6WbVu2hSbTb72v8rW+ei18j5h/Zt/4Jwf8KM+JvhXXtW8b3Hiq1+H2mXOk+F7I6UlmbCGeR2dppFkbz3CyMoO1B7V1P7R37DGkftFftAfDvx5d6o9hL4Hm3XVmtt5i61EsqTRRO29dgSVd3KtnPQda91oquZ80ZdYu69dXf8XuTZWkuklZ+m1vw07HyRB/wSe0Kw+N2oeIrfW9HOgap4h/4SO40288JWV7qCzElngj1Cbc8cDOc7AmRjhgctW9+z3/AME+9a/Z+1q00+z+K2vT/DvSrm9ubHwxFp8dsSbnOVublXJnVCcgFF59sivpmipilGPKtrW+Wn+WnboVJuTcnu3f56/5v1Pj7wl/wSy1PwZ8OfCujWnxPb7f8O9ffW/CN+/hyMjTBI7PNBPH53+kB2IO7chG3gY4rW+Ev/BL6z+Evjz4d+Ibbxlc3V/4OvtX1XUpJNMQNrV3qEQjeRf3m2AJhcLtkzjk96+q6KpSafMt/wDgJfikr97X3E7NOL2d/wAW3+r+8+WvgF/wTSj+DX7Rlj8Q7vxXp+pXemJeJBFp3hm30WS7+0ZBN28D+XMVUnG2KPJ5Oa+paKKV/dUeiD7Tl1YUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAf//Z)"
      ],
      "metadata": {
        "id": "lNqj4OTYiIj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's review each of these steps."
      ],
      "metadata": {
        "id": "y9zpP2iDiMVH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bth2GVAyYpCk"
      },
      "source": [
        "### Text standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider these two sentences:\n",
        "\n",
        "* “sunset came. i was staring at the Mexico sky. Isnt nature splendid??”\n",
        "* “Sunset came; I stared at the México sky. Isn't nature splendid?”\n",
        "\n",
        "They're very similar—in fact, they're almost identical. Yet, if you were to convert them to <font color='blue'>byte strings</font>, they would end up with very different representations, because “i” and “I” are two different characters, “Mexico” and “México” are two different words, “isnt” isn't “isn't,” and so on. A machine learning model doesn't know a priori that “i” and\n",
        "“I” are the same letter, that “é” is an “e” with an accent, or that “staring” and “stared” are two forms of the same verb.\n",
        "\n",
        "<font color='blue'>Text  standardization</font>  is  a  basic  form  of  feature  engineering  that  aims  to  <font color='blue'>erase  encoding  differences</font>  that  you  don't  want  your  model  to  have  to  deal  with.  It's  not exclusive  to  machine  learning,  either—you'd  have  to  do  the  same  thing  if  you  were building a search engine.\n",
        "\n",
        "One of the simplest and most widespread standardization  schemes is “convert to lowercase and remove punctuation characters.” Our two sentences would become\n",
        "\n",
        "* “sunset came i was staring at the mexico sky isnt nature splendid”\n",
        "* “sunset came i stared at the méxico sky isnt nature splendid”\n",
        "\n",
        "Much closer already. Another common transformation is to convert <font color='blue'>special characters</font> to a <font color='blue'>standard form</font>, such as replacing “é” with “e,” “æ” with “ae,” and so on. Our token “méxico” would then become “mexico”.\n",
        "\n",
        "Lastly, a much more advanced standardization pattern that is more rarely used in a machine learning context is <font color='blue'>stemming</font>: converting variations of a term (such as different  conjugated  forms  of  a  verb)  into  a  single  shared  representation,  like  turning “caught”  and  “been  catching”  into  “[catch]”  or  “cats”  into  “[cat]”.  With  stemming,\n",
        "“was staring” and “stared” would become something like “[stare]”, and our two similar sentences would finally end up with an identical encoding:\n",
        "\n",
        "* “sunset came i [stare] at the mexico sky isnt nature splendid”\n",
        "\n",
        "With these standardization techniques, your model will require <font color='blue'>less training data</font> and will <font color='blue'>generalize  better</font>—it won't  need  abundant  examples of  both  “Sunset”  and  “sunset” to learn that they mean the same thing, and it will be able to make sense of “México” even if it has only seen “mexico” in its training set. Of course, standardization may\n",
        "also  erase  some  amount  of  information,  so  always  keep  the  context  in  mind:  for instance,  if  you're  writing  a  model  that  <font color='blue'>extracts  questions</font>  from  interview  articles,  it should definitely treat <font color='blue'>?</font> as a separate token instead of dropping it, because it's a useful signal for this specific task."
      ],
      "metadata": {
        "id": "A9fTxjZQiuyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remark:** To store the human-readable characters on computers, we need to <font color='blue'>encode</font> them into <font color='blue'>bytes</font>. The rule that defines the encoding process is called encoding schema and commonly used ones include <font color='blue'>ASCII, UTF-8,</font> etc. ASCII converts each character into one byte. As one byte consists of 8 bits and each bit contains a 0 or 1, the total number of <font color='blue'>characters</font> ASCII can represent is <font color='blue'>2⁸=256</font>. This is more than enough for 26 English letters plus some commonly-used characters. See the [ASCII table](https://www.rapidtables.com/code/text/ascii-table.html) for more information.\n",
        "\n",
        "However, 256 characters are not enough for storing all the characters available to us. In light of that, people designed <font color='blue'>Unicode</font> in which each character will be encoded as a <font color='blue'>code point</font>. For instance, “H” will be represented as code point “U+0048”. According to [Wikipedia](https://en.wikipedia.org/wiki/Unicode), Unicode can include <font color='blue'>144,697 characters</font>. But again, the code point still can not be recognized by the computer, so we have “UTF-8” or other variants encoding schema to convert the code point to the byte. UTF-8 means the minimum length of bits to represent a character is 8. Therefore, in a similar manner, UTF-16 means the minimum length of bits is 16.\n",
        "\n",
        "There are many other formats to store characters on a computer."
      ],
      "metadata": {
        "id": "BRjqkH4OHQN5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16HVPKAIYpCl"
      },
      "source": [
        "### Text splitting (tokenization)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once  your  text  is  standardized,  you  need  to  break  it  up  into  units  to  be  <font color='blue'>vectorized</font>(tokens), a step called <font color='blue'>tokenization</font>. You could do this in three different ways:\n",
        "\n",
        "* <font color='blue'>Word-level  tokenization</font>—Where  tokens  are  space-separated  (or  punctuation-separated)  substrings.  A  variant  of  this  is  to  further  split  words  into  subwords when  applicable—for  instance,  treating  “staring”  as  “star+ing”  or  “called”  as“call+ed.”\n",
        "* <font color='blue'>N-gram  tokenization</font>—Where  tokens  are  groups  of N  consecutive  words.  For instance, “the cat” or “he was” would be 2-gram tokens (also called bigrams).\n",
        "* <font color='blue'>Character-level tokenization</font>—Where each  character is its  own token.  In  practice, this scheme is rarely used, and you only really see it in specialized contexts, like text generation or speech recognition.\n",
        "\n",
        "In general, you'll always use either <font color='blue'>word-level</font> or <font color='blue'>N-gram tokenization</font>. There are two kinds of text-processing models: those that <font color='blue'>care</font> about <font color='blue'>word order</font>, called <font color='blue'>sequence models</font>, and those that treat <font color='blue'>input words as a set</font>, discarding their original order, called <font color='blue'>bag-of-words models</font>. If you're building a sequence model, you'll use word-level tokenization, and if you're building a bag-of-words model, you'll use N-gram tokenization. N-grams are a way to artificially inject a small amount of local word order information into the model. Throughout this chapter, you'll learn more about each type of model and when to use them."
      ],
      "metadata": {
        "id": "WFMH2Z1U3Djs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8Z2PhesYpCl"
      },
      "source": [
        "### Vocabulary indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word N-grams are <font color='blue'>groups of N (or fewer)</font> consecutive words that you can extract from a sentence. The same concept may also be applied to characters instead of words.\n",
        "\n",
        "Here's a simple example. Consider the sentence “<font color='blue'>the cat sat on the mat.</font>” It may be decomposed into the following set of 2-grams:\n",
        "\n",
        "`{\"the\", \"the cat\", \"cat\", \"cat sat\", \"sat\",`\n",
        "\n",
        " `\"sat on\", \"on\", \"on the\", \"the mat\", \"mat\"}`\n",
        "\n",
        " It may also be decomposed into the following set of 3-grams:\n",
        "\n",
        " `{\"the\", \"the cat\", \"cat\", \"cat sat\", \"the cat sat\",`\n",
        "\n",
        " `\"sat\", \"sat on\", \"on\", \"cat sat on\", \"on the\", `\n",
        "\n",
        " `\"sat on the\", \"the mat\", \"mat\", \"on the mat\"}`\n",
        "\n",
        " Such a set is called a <font color='blue'>bag-of-2-grams</font> or <font color='blue'>bag-of-3-grams</font>, respectively. The term “bag” here refers to the fact that you're dealing with a set of tokens rather than a list or sequence: the tokens have no specific order. This family of tokenization methods is called <font color='blue'>bag-of-words</font> (or <font color='blue'>bag-of-N-grams</font>).\n",
        "\n",
        " Because bag-of-words isn't an order-preserving tokenization method (the tokens generated are understood as a set, not a sequence, and the general structure of the sentences is lost), it tends to be used in shallow language-processing models rather than in  deep  learning  models.  Extracting  N-grams  is  a  form  of  feature  engineering,  and deep learning sequence models do away with this manual approach, replacing it with hierarchical feature learning. <font color='blue'>One-dimensional convnets, recurrent neural networks</font>, and <font color='blue'>Transformers</font> are capable of <font color='blue'>learning representations</font> for groups of words and characters without <font color='blue'>being explicitly told</font> about the existence of such groups, by looking at continuous word or character sequences.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JZIHG6cI3qME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocabulary indexing"
      ],
      "metadata": {
        "id": "HlRmPxDi5gMs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once your text is split into tokens, you need to encode each token into a numerical representation. You could potentially do this in a stateless way, such as by hashing each token into a fixed binary vector, but in practice, the way you'd go about it is to <font color='blue'>build an  index</font>  of  all  terms  found  in  the  training  data  (the  <font color='blue'>vocabulary</font>), and  assign a unique integer to each entry in the vocabulary.\n",
        "\n",
        "Something like this:"
      ],
      "metadata": {
        "id": "HtUefqSJ5jmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Psuedocode\n",
        "\n",
        "vocabulary = {}                                                                 # Create an empty vocabulary dictionary\n",
        "for text in dataset:                                                            # Loop through all the text in the dataset and\n",
        "  text = standardize(text)                                                      # standardize and tokenize it\n",
        "  tokens = tokenize(text)\n",
        "  for token in tokens:\n",
        "    if token not in vocabulary:                                                 # If a token isn't in the vobulary dictionary,\n",
        "      vocabulary[token] = len(vocabulary)                                       # add a token whose value is the length of the vocabulary"
      ],
      "metadata": {
        "id": "qOap1-xo5qmc",
        "outputId": "ad1c4d74-f9d6-4994-bd68-58c1364d7d2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-746268b033b5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m                                                                 \u001b[0;31m# Create an empty vocabulary dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m                                                            \u001b[0;31m# Loop through all the text in the dataset and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m                                                      \u001b[0;31m# standardize and tokenize it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can then <font color='blue'>convert</font> that <font color='blue'>integer</font> into a vector encoding that can be processed by a neural network, like a <font color='blue'>one-hot</font> vector:"
      ],
      "metadata": {
        "id": "SjTNfvHU7Cdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Psuedocode\n",
        "\n",
        "def one_hot_encode_token(token):\n",
        "  vector = np.zeros((len(vocabulary),))\n",
        "  token_index = vocabulary[token]\n",
        "  vector[token_index] = 1\n",
        "  return vector"
      ],
      "metadata": {
        "id": "4NHyGPDz7Gd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that at this step it's common to <font color='blue'>restrict</font> the <font color='blue'>vocabulary</font> to only the <font color='blue'>top 20,000 or 30,000</font> most common words found in the training data. Any text dataset tends to feature an extremely large number of unique terms, most of which only show up once or twice—indexing  those  rare  terms  would  result  in  an  excessively  large  feature  space, where most features would have almost no information content.\n",
        "\n",
        "Remember when you were training your first deep learning models on the IMDB dataset in chapters 4 and 5? The data you were using from `keras.datasets.imdb` was already preprocessed into sequences of integers, where each integer stood for a given word. Back then, we used the setting <font color='blue'>num_words=10000</font>, in order to <font color='blue'>restrict</font> our vocabulary to the <font color='blue'>top 10,000</font> most common words found in the training data.\n",
        "\n",
        "Now, there's an important detail here that we shouldn't overlook: when we lookup a <font color='blue'>new token</font> in our vocabulary index, it <font color='blue'>may not</font> necessarily <font color='blue'>exist</font>. Your training data may not have contained any instance of the word <font color='blue'>cherimoya</font> (or maybe you excluded  it  from  your  index  because  it  was  too  rare),  so  doing `token_index=vocabulary[\"cherimoya\"]` may result in a `KeyError`. To handle this, you should use an  <font color='blue'>out  of  vocabulary</font>  index  (abbreviated  as <font color='blue'>OOV</font> *index*)—a  catch-all  for  any  token that  wasn't  in  the  index.  It's  usually  index  1:  you're  actually  doing\n",
        "```\n",
        "token_index=vocabulary.get(token,1).\n",
        "```\n",
        " When decoding a sequence of integers back into words, you'll replace 1 with something like “[UNK]” (which you'd call an “OOV token”).\n",
        "\n",
        "\"Why use 1 and not 0?” you may ask. That's because <font color='blue'>0</font> is <font color='blue'>already taken</font>. There are two  special  tokens  that  you  will  commonly  use:  the  <font color='blue'>OOV  token  (index  1)</font>,  and  the <font color='blue'>mask token (index 0)</font>. While the OOV token means “here was a word we did not recognize,” the mask token tells us “ignore me, I'm not a word.” You'd use it in particular to pad  sequence  data:  because  data  batches  need  to  be  contiguous,  all  sequences  in  a batch  of  sequence  data  must  have  the  same  length,  so  shorter  sequences  should  be padded to the length of the longest sequence. If you want to make a batch of data with the sequences `[5,7,124,4,89]` and `[8,34,21]`, it would have to look like this:\n",
        "\n",
        "```\n",
        "[[5,  7, 124, 4, 89]\n",
        "[8, 34,  21, 0,  0]]\n",
        "```\n",
        "\n",
        "The batches of integer sequences for the IMDB dataset that you worked with in chapters 4 and 5 were padded with zeros in this way."
      ],
      "metadata": {
        "id": "wWij6h3Z7KBE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6y4OPvjYpCm"
      },
      "source": [
        "### Using the TextVectorization layer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remark:**  A <font color='blue'>method</font> is on an object or is <font color='blue'>static</font> in class. A <font color='blue'>function</font> is <font color='blue'>independent</font> of any object (and outside of any class).\n",
        "\n",
        "\n",
        "*   For Java and C#, there are only methods.\n",
        "*   For C, there are only functions.\n",
        "*   For C++ and Python, it depends on whether or not you're in a class.\n",
        "\n",
        "In other words:\n",
        "\n",
        "* Function: Standalone feature or functionality.\n",
        "* Method: One way of doing something, which has different approaches or methods, but related to the same aspect (aka class).\n",
        "\n",
        "More information about this (in Youtube format) is described [here](https://www.youtube.com/watch?v=qX5TpBzpIwo).\n",
        "\n"
      ],
      "metadata": {
        "id": "5rcWzwpI9vJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every  step  I've  introduced  so  far  can be implemented in Python. Maybe you could write something like this:"
      ],
      "metadata": {
        "id": "OQivi_cU9K8f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U53PCNfdYpCm"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "class Vectorizer:                                                               # Python is an object oriented programming language. So,\n",
        "                                                                                # we will create a Vectorizer class.\n",
        "                                                                                # In all of the examples below, a function that is\n",
        "                                                                                # a member of a class is called a method.\n",
        "    # self is an object instance, which is the first parameter\n",
        "    def standardize(self, text):                                                # Create a method to standardize text\n",
        "        text = text.lower()\n",
        "        return \"\".join(char for char in text if char not in string.punctuation)\n",
        "\n",
        "    def tokenize(self, text):                                                   # Create a method to tokenize text\n",
        "        text = self.standardize(text)\n",
        "        return text.split() # splits the text into a list\n",
        "\n",
        "    def make_vocabulary(self, dataset):                                         # Create a method to make the vocabulary for a\n",
        "                                                                                # given dataset\n",
        "        self.vocabulary = {\"\": 0, \"[UNK]\": 1}\n",
        "        for text in dataset:\n",
        "            text = self.standardize(text)\n",
        "            tokens = self.tokenize(text)\n",
        "            for token in tokens:\n",
        "                if token not in self.vocabulary:\n",
        "                    self.vocabulary[token] = len(self.vocabulary)\n",
        "        self.inverse_vocabulary = dict(\n",
        "            (v, k) for k, v in self.vocabulary.items())\n",
        "\n",
        "    def encode(self, text):                                                     # Create a method to encode text\n",
        "        text = self.standardize(text)\n",
        "        tokens = self.tokenize(text)\n",
        "        return [self.vocabulary.get(token, 1) for token in tokens]\n",
        "\n",
        "    def decode(self, int_sequence):                                             # Create a method to decode int_sequence\n",
        "        return \" \".join(\n",
        "            self.inverse_vocabulary.get(i, \"[UNK]\") for i in int_sequence)\n",
        "\n",
        "vectorizer = Vectorizer()\n",
        "dataset = [                                                                     # Haiku by the poet Hokushi\n",
        "    \"I write, erase, rewrite\",\n",
        "    \"Erase again, and then\",\n",
        "    \"A poppy blooms.\",\n",
        "]\n",
        "vectorizer.make_vocabulary(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It does the job:"
      ],
      "metadata": {
        "id": "rhMEJohl_hMs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-4I5lGmYpCo",
        "outputId": "5c822ec2-53e3-41e4-8097-6b4cf64928c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 3, 5, 7, 1, 5, 6]\n"
          ]
        }
      ],
      "source": [
        "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
        "encoded_sentence = vectorizer.encode(test_sentence)\n",
        "print(encoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBecKs8yYpCp",
        "outputId": "781465a7-f4c3-467a-fef6-b4a211875113",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i write rewrite and [UNK] rewrite again\n"
          ]
        }
      ],
      "source": [
        "decoded_sentence = vectorizer.decode(encoded_sentence)\n",
        "print(decoded_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However,  using  something  like  this  wouldn't  be  very  performant.  In  practice,  you'll work with the Keras <font color='blue'>TextVectorization</font> layer, which is fast and efficient and can be dropped directly into a `tf.data` pipeline or a Keras model.\n",
        "\n",
        "This is what the *TextVectorization* layer looks like:"
      ],
      "metadata": {
        "id": "dYIhRMtuAwAQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDj4h6--YpCp"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"int\",                                                          # Configures the layer to return sequences of words\n",
        "                                                                                # encoded as integer indices. There are several other\n",
        "                                                                                # output modes available, discussed later.\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, the *TextVectorization* layer will use the setting <font color='blue'>convert to lowercase and remove punctuation</font> for <font color='blue'>text standardization</font>, and <font color='blue'>split on whitespace</font> for <font color='blue'>tokenization</font>. But importantly, you can provide custom functions for standardization and tokenization, which means the layer is flexible enough to handle any use case. Note that such  custom  functions  should  operate on `tf.string` tensors, not regular Python strings. For instance, the default layer behavior is equivalent to the following:"
      ],
      "metadata": {
        "id": "oD6ebtQcBDmI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTWOvYdxYpCq"
      },
      "outputs": [],
      "source": [
        "import re                                                                       # Regular expression operations\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "def custom_standardization_fn(string_tensor):\n",
        "    lowercase_string = tf.strings.lower(string_tensor)                          # Converts strings to lowercase.\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\")             # Replace punctuation characters with the empty string.\n",
        "\n",
        "def custom_split_fn(string_tensor):\n",
        "    return tf.strings.split(string_tensor)                                      # Split strings on whitespace.\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"int\",\n",
        "    standardize=custom_standardization_fn,\n",
        "    split=custom_split_fn,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remark:** In pure Python, there are a bunch of ways to <font color='blue'>strip punction</font> from a <font color='blue'>string</font>. Here are 4 different methods as shown in [this](https://stackoverflow.com/a/266162) StackOverflow answer (with some more information [here](https://docs.python.org/3/library/stdtypes.html#str.translate)):"
      ],
      "metadata": {
        "id": "2t6lRQgdChzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import re, string, timeit\n",
        "import timeit\n",
        "\n",
        "s = \"string. With. Punctuation!\"\n",
        "exclude = set(string.punctuation)\n",
        "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "\n",
        "def test_set(s):\n",
        "    return ''.join(ch for ch in s if ch not in exclude)\n",
        "\n",
        "def test_re(s):\n",
        "    return regex.sub('', s)\n",
        "\n",
        "def test_trans(s):\n",
        "    return s.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "def test_repl(s):\n",
        "    for c in string.punctuation:\n",
        "        s=s.replace(c,\"\")\n",
        "    return s\n",
        "\n",
        "print(\"sets      :\",timeit.Timer('f(s)', 'from __main__ import s,test_set as f').timeit(1000000))\n",
        "print(\"regex     :\",timeit.Timer('f(s)', 'from __main__ import s,test_re as f').timeit(1000000))\n",
        "print(\"translate :\",timeit.Timer('f(s)', 'from __main__ import s,test_trans as f').timeit(1000000))\n",
        "print(\"replace   :\",timeit.Timer('f(s)', 'from __main__ import s,test_repl as f').timeit(1000000))"
      ],
      "metadata": {
        "id": "ikcYqBWvC9a5",
        "outputId": "266cc074-3fd0-420e-bce4-c080a39d5246",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sets      : 4.192186221000156\n",
            "regex     : 0.851805393999939\n",
            "translate : 3.8592227490000823\n",
            "replace   : 3.0160426859999916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_set(s))\n",
        "print(test_re(s))\n",
        "print(test_trans(s))\n",
        "print(test_repl(s))"
      ],
      "metadata": {
        "id": "l37o65flEF9c",
        "outputId": "4c5e8dfc-97b2-4fed-e50e-d6bec9ef5eb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "string With Punctuation\n",
            "string With Punctuation\n",
            "string With Punctuation\n",
            "string With Punctuation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To  index  the  vocabulary  of  a  text  corpus,  just  call  the <font color='blue'>adapt()</font> method of the layer with a *Dataset* object that yields strings, or just with a list of Python strings:\n",
        "\n",
        "**Remark:** More about the `adapt()` method [here](https://www.tensorflow.org/guide/keras/preprocessing_layers#the_adapt_method)."
      ],
      "metadata": {
        "id": "Uneu32mtCM2o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sTPKmbfYpCq"
      },
      "outputs": [],
      "source": [
        "dataset = [\n",
        "    \"I write, erase, rewrite\",\n",
        "    \"Erase again, and then\",\n",
        "    \"A poppy blooms.\",\n",
        "]\n",
        "text_vectorization.adapt(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that you can <font color='blue'>retrieve</font> the <font color='blue'>computed vocabulary</font> via <font color='blue'>get_vocabulary()</font>—this can be useful if you need to convert text encoded as integer sequences back into words. The  first  two  entries  in  the  vocabulary  are  the  mask  token  (index  0)  and  the  OOV token (index 1). Entries in the vocabulary list are <font color='blue'>sorted</font> by <font color='blue'>frequency</font>, so with a real-world dataset, very common words like “the” or “a” would come first."
      ],
      "metadata": {
        "id": "uVrITlCOCZZA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tnB3H12YpCq"
      },
      "source": [
        "**Displaying the vocabulary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z8sFB2_YpCr",
        "outputId": "55323fc4-c373-4534-b1c6-7601cf5ea451",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'erase',\n",
              " 'write',\n",
              " 'then',\n",
              " 'rewrite',\n",
              " 'poppy',\n",
              " 'i',\n",
              " 'blooms',\n",
              " 'and',\n",
              " 'again',\n",
              " 'a']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "text_vectorization.get_vocabulary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a demonstration, let’s try to encode and then decode an example sentence:"
      ],
      "metadata": {
        "id": "Rp4RJgBQJHbM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_qGg-r9YpCr",
        "outputId": "04202550-57ed-4b97-97ab-90aa7f4de8e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 7  3  5  9  1  5 10], shape=(7,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
        "encoded_sentence = text_vectorization(test_sentence)\n",
        "print(encoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6Di-74OYpCs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "485f473e-72fa-4f67-c3c3-219a3dc7beba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i write rewrite and [UNK] rewrite again\n"
          ]
        }
      ],
      "source": [
        "inverse_vocab = dict(enumerate(vocabulary))\n",
        "decoded_sentence = \" \".join(inverse_vocab[int(i)] for i in encoded_sentence)\n",
        "print(decoded_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using the TextVectorization layer in a `tf.data` pipeline or as part of a model"
      ],
      "metadata": {
        "id": "SFGDDip_JxJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importantly, because *TextVectorization* is mostly a dictionary lookup operation, it <font color='blue'>can't be executed</font> on a <font color='blue'>GPU (or TPU)</font>—only on a CPU. So if you're training your modelon a GPU, your *TextVectorization* layer will run on the CPU before sending its output to the GPU. This has important performance implications.\n",
        "\n",
        "There are two ways we could use our *TextVectorization* layer. The first option is to put it in the `tf.data` pipeline, like this:\n",
        "\n",
        "**Remark:** Python's <font color='blue'>map()</font> is a built-in function that allows you to process and transform all the items in an iterable <font color='blue'>without using an explicit for loop</font>, a technique commonly known as mapping. `map()` is useful when you need to apply a <font color='blue'>transformation function</font> to each item in an <font color='blue'>iterable</font> and <font color='blue'>transform</font> them into a <font color='blue'>new iterable</font>. `map()` is one of the tools that support a functional programming style in Python. More information about this [here](https://realpython.com/python-map-function/)."
      ],
      "metadata": {
        "id": "Zd-bPQWDJ76W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Psuedocode\n",
        "\n",
        "int_sequence_dataset = string_dataset.map(                                      # string_dataset would be a dataset that yields string tensors.\n",
        "    text_vectorization,\n",
        "    num_parallel_calls=4)                                                       # The num_parallel_calls argument is used to parallelize the\n",
        "                                                                                # map() call across multiple CPU cores"
      ],
      "metadata": {
        "id": "d_78tFGVKS49",
        "outputId": "b0324771-e1eb-447a-a046-9eb4bf7cef1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0ed4de694139>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m int_sequence_dataset = string_dataset.map(                                      # string_dataset would be a dataset that yields string tensors.\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtext_vectorization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     num_parallel_calls=4)                                                       # The num_parallel_calls argument is used to parallelize the\n\u001b[1;32m      4\u001b[0m                                                                                 \u001b[0;31m# map() call across multiple CPU cores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'string_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second option is to make it part of the model (after all, it's a Keras layer), like this"
      ],
      "metadata": {
        "id": "Zx2gcbbRKnwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Psuedocode\n",
        "\n",
        "text_input = keras.Input(shape=(), dtype=\"string\")                              # Create a symbolic input that expects strings.\n",
        "vectorized_text = text_vectorization(text_input)                                # Apply the text vectorization layer to it.\n",
        "embedded_input = keras.layers.Embedding(...)(vectorized_text)                   # You can keep chaining new layers on top —\n",
        "output = ...                                                                    # just your regular Functional API mode\n",
        "model = keras.Model(text_input, output)"
      ],
      "metadata": {
        "id": "mfvmlbQDKsa9",
        "outputId": "9d32857c-9766-4bc7-f603-693394a2656f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c034cd0acee3>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Psuedocode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtext_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"string\"\u001b[0m\u001b[0;34m)\u001b[0m                              \u001b[0;31m# Create a symbolic input that expects strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mvectorized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_vectorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_input\u001b[0m\u001b[0;34m)\u001b[0m                                \u001b[0;31m# Apply the text vectorization layer to it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0membedded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized_text\u001b[0m\u001b[0;34m)\u001b[0m                   \u001b[0;31m# You can keep chaining new layers on top —\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's an important difference between the two: if the <font color='blue'>vectorization step</font> is <font color='blue'>part</font> of the <font color='blue'>model</font>, it will happen <font color='blue'>synchronously</font> with the rest of the model. This means that at each training step, the rest of the model (placed on the GPU) will have to <font color='blue'>wait</font> for the output of the *TextVectorization* layer (placed on the CPU) to be ready in order to get to work. Meanwhile, putting the layer in the `tf.data` pipeline enables you to do <font color='blue'>asynchronous preprocessing</font> of your data on CPU: while the GPU runs the model on one batch of vectorized data, the CPU stays busy by vectorizing the next batch of raw strings.\n",
        "\n",
        "So if you're training the model on GPU or TPU, you'll probably want to go with the <font color='blue'>first option</font> to get the best performance. This is what we will do in all practical examples throughout this chapter. When training on a CPU, though, synchronous processing is fine: you will get 100% utilization of your cores regardless of which option you go with.\n",
        "\n",
        "Now, if you were to export our model to a <font color='blue'>production environment</font>, you would want to <font color='blue'>ship</font> a model that accepts raw strings as input, like in the code snippet for the <font color='blue'>second option</font>  above—otherwise  you  would  have  to  reimplement  text  standardization  and tokenization in your production environment (maybe in JavaScript?), and you would face  the  risk of  introducing  small  preprocessing  discrepancies  that  would  hurt  the model's accuracy. Thankfully, the <font color='blue'>TextVectorization</font> layer enables you to <font color='blue'>include text preprocessing</font> right into your <font color='blue'>model</font>, making it easier to deploy—even if you were originally using the layer as part of a `tf.data` pipeline. In the sidebar “Exporting a model  that  processes  raw  strings,”  you'll  learn  how  to  export  an  inference-only trained model that incorporates text preprocessing.\n",
        "\n",
        "You've  now  learned  everything  you  need  to  know  about  text  preprocessing—let's move on to the modeling stage.\n"
      ],
      "metadata": {
        "id": "Dqbp79sBLNIO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DovQ-1tmYpCs"
      },
      "source": [
        "## Two approaches for representing groups of words: Sets and sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How a machine learning model should represent <font color='blue'>individual words</font> is a relatively uncontroversial question: they're <font color='blue'>categorical features</font> (values from a predefined set), and we know how to handle those. They should be encoded as <font color='blue'>dimensions</font> in a <font color='blue'>feature space</font>, or as <font color='blue'>category vectors</font> (word vectors in this case). A much more problematic question, however, is how to *encode the way words are woven into sentences*: <font color='blue'>word order</font>.\n",
        "\n",
        "The problem of order in natural language is an interesting one: unlike the steps of a timeseries, <font color='blue'>words in a sentence don't</font> have a <font color='blue'>natural, canonical order</font>. Different languages order similar words in very different ways. For instance, the sentence structure of <font color='blue'>English</font> is quite <font color='blue'>different</font> from that of <font color='blue'>Japanese</font>. Even within a given language, you can typically say the <font color='blue'>same thing</font> in <font color='blue'>different ways</font> by reshuffling the words a bit. Even further, if you fully randomize the words in a short sentence, you can still largely figure out what it was saying—though in many cases significant ambiguity seems to arise. <font color='blue'>Order</font> is clearly <font color='blue'>important</font>, but its relationship to meaning isn't straightforward.\n",
        "\n",
        "How to represent word order is the pivotal question from which different kinds of NLP  architectures spring.  The simplest thing  you  could  do  is <font color='blue'>just discard order</font> and treat <font color='blue'>text</font> as an <font color='blue'>unordered set of words</font>—this gives you <font color='blue'>bag-of-words models</font>.  You  could also decide that words should be <font color='blue'>processed strictly in the order</font> in <font color='blue'>which they appear</font>, one at a time, like steps in a timeseries—you could then leverage the recurrent models from  the  last  chapter.  Finally,  a  <font color='blue'>hybrid  approach</font>  is  also  possible:  the  <font color='blue'>Transformer architecture</font> is technically <font color='blue'>order-agnostic</font>, yet it injects <font color='blue'>word-position information</font> into the <font color='blue'>representations  it  processes</font>,  which  enables  it  to  simultaneously  look  at  different parts of a sentence (unlike RNNs) while still being order-aware. Because they take into account <font color='blue'>word order</font>, both <font color='blue'>RNNs</font> and <font color='blue'>Transformers</font> are called <font color='blue'>sequence models</font>.\n",
        "\n",
        "Historically, most <font color='blue'>early applications</font> of machine learning to NLP just involved <font color='blue'>bag-of-words models</font>. Interest in <font color='blue'>sequence models</font> only started rising in <font color='blue'>2015</font>, with the <font color='blue'>rebirth</font> of <font color='blue'>recurrent neural networks</font>. Today, both approaches remain relevant. Let's see how they work, and when to leverage which.\n",
        "\n",
        "We'll demonstrate each approach on a well-known text classification <font color='blue'>benchmark</font>: the  <font color='blue'>IMDB  movie  review  sentiment-classification</font>  dataset.  In  chapters  4  and  5,  you worked  with  a  prevectorized  version  of  the  IMDB  dataset;  now,  let's  process  the  raw IMDB  text  data,  just  like  you  would  do  when  approaching  a  new  text-classification problem in the real world."
      ],
      "metadata": {
        "id": "-Fy9JYffMljJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cU9Yq_qYpCt"
      },
      "source": [
        "### Preparing the IMDB movie reviews data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's  start  by  downloading  the  dataset  from  the  Stanford  page  of  Andrew  Maas  anduncompressing it:"
      ],
      "metadata": {
        "id": "Zqx9gLhlNhPA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Je_rsLyuYpCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680bc99a-1354-4ddc-c27e-ede5a31114cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  8604k      0  0:00:09  0:00:09 --:--:-- 15.7M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You're left with a directory named <font color='blue'>aclImdb</font>, with the following structure:\n",
        "\n",
        "```\n",
        "aclImdb/\n",
        "...train/\n",
        "......pos/\n",
        "......neg/\n",
        "...test/\n",
        "......pos/\n",
        "......neg/\n",
        "```\n",
        "\n",
        "For instance, the <font color='blue'>train/pos/</font> directory contains a set of <font color='blue'>12,500</font> text files, each of which contains the <font color='blue'>text body</font> of a <font color='blue'>positive-sentiment movie review</font> to be used as training data. The <font color='blue'>negative-sentiment</font> reviews live in the <font color='blue'>neg</font> directories. In total, there are 25,000 text files for training and another 25,000 for testing.\n",
        "\n",
        "There's also a <font color='blue'>train/unsup</font> subdirectory in there, which we don't need. Let's delete it:\n"
      ],
      "metadata": {
        "id": "5-iAFK24NnaQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLSYZZHKYpCu"
      },
      "outputs": [],
      "source": [
        "!rm -r aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take  a  look  at  the  content  of  a  few  of  these  text  files.  Whether  you're  working  with text data or image data, remember to always <font color='blue'>inspect what your data looks like</font> before you dive into modeling it. It will ground your intuition about what your model is actually doing:"
      ],
      "metadata": {
        "id": "vNI7NHdYN_do"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omHBzUWdYpCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21e52cb4-af51-4e1b-d2e6-ca8336147bc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ],
      "source": [
        "!cat aclImdb/train/pos/4077_10.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's prepare a <font color='blue'>validation set</font> by setting apart <font color='blue'>20%</font> of the training text files in a new directory, <font color='blue'>aclImdb/val</font>"
      ],
      "metadata": {
        "id": "PS4D8hVxOGxp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xP8QfpCLYpCw"
      },
      "outputs": [],
      "source": [
        "import os, pathlib, shutil, random\n",
        "\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(val_dir / category, exist_ok=True)                              # Note: I manually added exist_ok=True\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1337).shuffle(files)                                          # Shuffle the list of training files using a seed, to ensure we\n",
        "                                                                                # get the same validation set every time we run the code.\n",
        "    num_val_samples = int(0.2 * len(files))                                     # Take 20% of the training files to use for validation.\n",
        "    val_files = files[-num_val_samples:]\n",
        "    for fname in val_files:\n",
        "        shutil.move(train_dir / category / fname,                               # Move the files to aclImdb/val/neg and aclImdb/val/pos.\n",
        "                    val_dir / category / fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember how, in chapter 8, we used the <font color='blue'>image_dataset_from_directory</font> utility to create a batched *Dataset* of images and their labels for a directory structure? You can do the exact same thing for text files using the <font color='blue'>text_dataset_from_directory</font> utility. Let's create three *Dataset* objects for training, validation, and testing:"
      ],
      "metadata": {
        "id": "OV8a0zmrPD3h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSWZjgUHYpCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97272502-187f-464f-e486-52ccfc578cf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(                             # Running this line should output “Found 20000 files\n",
        "    \"aclImdb/train\", batch_size=batch_size                                      # belonging to 2 classes”; if you see “Found 70000 files\n",
        ")                                                                               # belonging to 3 classes,” it means you forgot to delete\n",
        "val_ds = keras.utils.text_dataset_from_directory(                               # the aclImdb/train/unsup directory.\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These datasets yield inputs that are TensorFlow <font color='blue'>tf.string</font> tensors and targets that are <font color='blue'>int32</font> tensors encoding the value “0” or “1.”"
      ],
      "metadata": {
        "id": "lkwsoVQOPyYC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qifAdbFYpCy"
      },
      "source": [
        "**Displaying the shapes and dtypes of the first batch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqGrg8ZUYpCy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa68f205-2a3c-47e6-dbbf-4cfc010a0962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(b\"If this is supposed to be the black experience, let me out at either the front or back door.<br /><br />A mama's boy one day sees 2 young hoods walk by and from then on it's all down hill for him. Angela Bassett, the one shining grace in this film, plays his over protective, religious mother. Despite her anger at how his life has turned, by the middle of the picture, she really decides to accept this. She allows his friends to come in and suddenly it's all right to use the profanity as long as it's not in front of the children.<br /><br />This is a sad state of affairs regarding gangster rap. You knew where this film was heading.<br /><br />I literally laughed out loud when at the end, when Bassett is accompanying her son's body for burial, she states that while his life had been cut short at age 24, he had become a man. What man? He had been a convicted criminal, wrote the most atrocious rap music with constant vulgarity,and scorned society. That scene in the classroom where he tells a teacher that as a sanitation worker, he will earn more than the teacher is a perfect example of what goes on in our schools. The complete and utter lack of respect for the teacher.<br /><br />The east coast, west coast gang rap rivalry is never fully explained. All we see are guns blazing.<br /><br />A terrible picture doing nothing to prevent gang violence. What horrible role models are these rap singers and their foul music. The African American community should take umbrage at their very being. Who was this classless fat slob who portrayed Biggie? He made Rerun from the old television show look thin by comparison. I know it was the streets of Bedford Stuyvesant that changed this chubby little boy into the vulgar monster that he was. What a sorry state of affairs when this is called motion picture entertainment.\", shape=(), dtype=string)\n",
            "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All set. Now let's try learning something from this data."
      ],
      "metadata": {
        "id": "FW9hJlBgP5tC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wS6VPPUYpCz"
      },
      "source": [
        "### Processing words as a set: The bag-of-words approach"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The  <font color='blue'>simplest</font>  way  to  <font color='blue'>encode</font>  a  <font color='blue'>piece  of  text</font>  for  processing  by  a  machine  learning model is to <font color='blue'>discard order</font> and treat it as a <font color='blue'>set</font> (a “bag”) of <font color='blue'>tokens</font>. You could either look at  individual  words  (unigrams),  or  try  to  recover  some  local  order  information  by looking at groups of consecutive token (N-grams)."
      ],
      "metadata": {
        "id": "2oFnZ3YBP_Cb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BszBZCnlYpCz"
      },
      "source": [
        "#### Single words (unigrams) with binary encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you use a bag of <font color='blue'>single words</font>, the sentence “the cat sat on the mat” becomes\n",
        "\n",
        "`{\"cat\", \"mat\", \"on\", \"sat\", \"the\"}`\n",
        "\n",
        "The main advantage of this encoding is that you can represent an <font color='blue'>entire text</font> as a <font color='blue'>single  vector</font>,  where  each  entry  is  a  presence  indicator  for  a  given  word.  For  instance, using  binary  encoding  (multi-hot),  you'd  encode  a  text  as  a  vector  with  as  <font color='blue'>many dimensions</font>  as  there  are  <font color='blue'>words  in  your  vocabulary</font>—with  0s  almost  everywhere  and some  1s  for  dimensions  that  encode  words  present  in  the  text.  This  is  what  we  did when we worked with text data in chapters 4 and 5. Let's try this on our task.\n",
        "\n",
        "First, let's process our raw text datasets with a *TextVectorization* layer so that they  yield  <font color='blue'>multi-hot  encoded</font>  binary  word  vectors.  Our  layer  will  only  look  at  single words (that is to say, *unigrams*).\n",
        "\n",
        "**Remark:** Multi-hot encoding is explained [here](https://stats.stackexchange.com/questions/467633/what-exactly-is-multi-hot-encoding-and-how-is-it-different-from-one-hot)."
      ],
      "metadata": {
        "id": "sUC-BJuqQKoC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNyFTKNBYpCz"
      },
      "source": [
        "**Preprocessing our datasets with a `TextVectorization` layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCKXCU8vYpC0"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=20000,                                                           # Limit the vocabulary to the 20,000 most frequent words.\n",
        "                                                                                # Otherwise we’d be indexing every word in the training data—\n",
        "                                                                                # potentially tens of thousands of terms that only occur once\n",
        "                                                                                # or twice and thus aren’t informative. In general, 20,000 is\n",
        "                                                                                # the right vocabulary size for text classification\n",
        "    output_mode=\"multi_hot\",                                                    # Encode the output tokens as multi-hot binary vectors.\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)                               # Prepare a dataset that only yields raw text inputs (no labels).\n",
        "text_vectorization.adapt(text_only_train_ds)                                    # Use that dataset to index the dataset vocabulary via the\n",
        "                                                                                # adapt() method\n",
        "\n",
        "binary_1gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),                                    # Prepare processed versions of our training, validation,\n",
        "    num_parallel_calls=4)                                                       # and test dataset.\n",
        "binary_1gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)                                                       # Make sure to specify num_parallel_calls to leverage\n",
        "binary_1gram_test_ds = test_ds.map(                                             # multiple CPU cores.\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can try to inspect the output of one of these datasets."
      ],
      "metadata": {
        "id": "HJqHcB-cQuro"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7yFUT1RYpC0"
      },
      "source": [
        "**Inspecting the output of our binary unigram dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bu2stfUIYpC0",
        "outputId": "72d54e60-ecd2-4998-da9e-a4f8be9ef1eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32, 20000)\n",
            "inputs.dtype: <dtype: 'float32'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in binary_1gram_train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)                                        # Inputs are batches of 20,000-dimensional vectors\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])                                              # These vectors consist entirely of ones and zeros\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's write a <font color='blue'>reusable model-building function</font> that we'll use in all of the experiments in this section."
      ],
      "metadata": {
        "id": "n7TalTGXgWfJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P0ed44mYpC0"
      },
      "source": [
        "**Our model-building utility**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmUd0q_CYpC1"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model(max_tokens=20000, hidden_dim=16):\n",
        "    inputs = keras.Input(shape=(max_tokens,))\n",
        "    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's test our model."
      ],
      "metadata": {
        "id": "1S80S9abgnmT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8yi7enMYpC2"
      },
      "source": [
        "**Training and testing the binary unigram model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqQ5y2QpYpC2",
        "outputId": "9f9168eb-da20-4f51-83a3-832569cff75c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 10s 15ms/step - loss: 0.4045 - accuracy: 0.8288 - val_loss: 0.2933 - val_accuracy: 0.8848\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2637 - accuracy: 0.9013 - val_loss: 0.2913 - val_accuracy: 0.8906\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2352 - accuracy: 0.9172 - val_loss: 0.3044 - val_accuracy: 0.8896\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2224 - accuracy: 0.9244 - val_loss: 0.3169 - val_accuracy: 0.8890\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2133 - accuracy: 0.9305 - val_loss: 0.3325 - val_accuracy: 0.8856\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2029 - accuracy: 0.9338 - val_loss: 0.3414 - val_accuracy: 0.8896\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2026 - accuracy: 0.9381 - val_loss: 0.3518 - val_accuracy: 0.8862\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2028 - accuracy: 0.9365 - val_loss: 0.3680 - val_accuracy: 0.8814\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2004 - accuracy: 0.9390 - val_loss: 0.3694 - val_accuracy: 0.8820\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1983 - accuracy: 0.9410 - val_loss: 0.3771 - val_accuracy: 0.8816\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.2874 - accuracy: 0.8856\n",
            "Test acc: 0.886\n"
          ]
        }
      ],
      "source": [
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\",                       # i.e., binary classification on 1-grams\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(binary_1gram_train_ds.cache(),                                        # We call cache() on the datasets to cache them in memory: this way\n",
        "          validation_data=binary_1gram_val_ds.cache(),                          # we will only do the prepocessing once, during the first epoch, and\n",
        "          epochs=10,                                                            # we'll reuse the proprocessed texts for the following epochs.\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"binary_1gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gets us to a test accuracy of <font color='blue'>88.6%</font>. Note that in this case, since the data is a <font color='blue'>balanced two-class classification dataset</font> (there are many positive samples as negative samples), the <font color='blue'>naive baseline</font> we could reach without training an actual model would only be <font color='blue'>50%</font>. Meanwhile, the best score that can be achieved on this dataset without leveraging external data is around 95% test accuracy."
      ],
      "metadata": {
        "id": "fPdG2NoShRIZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2sMu5b7YpC2"
      },
      "source": [
        "#### Bigrams with binary encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course, <font color='blue'>discarding</font> word order is <font color='blue'>very reductive</font>, because even <font color='blue'>atomic concepts</font> can be expressed via <font color='blue'>multiple words</font>: the terms \"United States\" conveys a concept that is quite distinct from the meaning of the words \"states\" and \"united\" taken separately. For this reason, you will usually end up <font color='blue'>re-injecting local order information</font> into your *bag-of-words* representation by looking at N-grams rather than single words (most commonly, bigrams).\n",
        "\n",
        "With bigrams, the sentence “the cat sat on the mat” becomes\n",
        "\n",
        "\n",
        "```\n",
        "{\"the\", \"the cat\", \"cat\", \"cat sat\", \"sat\",\n",
        " \"sat on\", \"on\", \"on the\", \"the\", \"the mat\", \"mat\"}\n",
        "```\n",
        "\n",
        "The *TextVectorization* layer can be configured to <font color='blue'>return arbitrary N-grams</font>: bigrams, trigrams, etc. Just pass in `ngrams=N` as an argument in the code below.\n"
      ],
      "metadata": {
        "id": "Tpak62SCh9Hw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhoZ_Wj6YpC3"
      },
      "source": [
        "**Configuring the `TextVectorization` layer to return bigrams**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHTjWNbuYpC3"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test how our models performs when trained on such <font color='blue'>binary-encoded</font> bags of <font color='blue'>bigrams</font>."
      ],
      "metadata": {
        "id": "g8teWb0xj7fk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzkgUQSfYpC3"
      },
      "source": [
        "**Training and testing the binary bigram model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCVxdGNjYpC3",
        "outputId": "e43c0d2f-a750-4c0d-8fa0-80c16cd9f7f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 7s 10ms/step - loss: 0.3758 - accuracy: 0.8464 - val_loss: 0.2726 - val_accuracy: 0.8916\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2355 - accuracy: 0.9178 - val_loss: 0.2759 - val_accuracy: 0.8964\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2041 - accuracy: 0.9335 - val_loss: 0.2947 - val_accuracy: 0.8964\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1817 - accuracy: 0.9433 - val_loss: 0.3119 - val_accuracy: 0.8962\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1707 - accuracy: 0.9505 - val_loss: 0.3346 - val_accuracy: 0.8968\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1666 - accuracy: 0.9534 - val_loss: 0.3506 - val_accuracy: 0.8942\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1547 - accuracy: 0.9560 - val_loss: 0.3541 - val_accuracy: 0.8984\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1554 - accuracy: 0.9574 - val_loss: 0.3689 - val_accuracy: 0.8948\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1583 - accuracy: 0.9578 - val_loss: 0.3818 - val_accuracy: 0.8922\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1584 - accuracy: 0.9596 - val_loss: 0.3886 - val_accuracy: 0.8928\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.2660 - accuracy: 0.8972\n",
            "Test acc: 0.897\n"
          ]
        }
      ],
      "source": [
        "text_vectorization.adapt(text_only_train_ds)\n",
        "binary_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(binary_2gram_train_ds.cache(),\n",
        "          validation_data=binary_2gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"binary_2gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now getting an improved test accuracy of <font color='blue'>89.7%</font>. It turns out that local order is pretty important."
      ],
      "metadata": {
        "id": "wkY4emKYkYz_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swdPiSxuYpC4"
      },
      "source": [
        "#### Bigrams with TF-IDF encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also add a bit more information to this representation by counting how many times each word or N-gram occurs, that is to say, by taking the histogram of the words over the text. The histogram of\n",
        "```\n",
        "“the cat sat on the mat”\n",
        "```\n",
        "is\n",
        "\n",
        "```\n",
        "{\"the\": 2, \"the cat\": 1, \"cat\": 1, \"cat sat\": 1, \"sat\": 1,\n",
        " \"sat on\": 1, \"on\": 1, \"on the\": 1, \"the mat\": 1, \"mat\": 1}\n",
        "```\n",
        "\n",
        "If you're doing <font color='blue'>text classification</font>, knowing <font color='blue'>how many times</font> a <font color='blue'>word occurs</font> in a sample is <font color='blue'>critical</font>: any sufficiently long movie review may contain the word \"terrible\" regardless of sentiment, but a review that contains <font color='blue'>many instances</font> of the word \"terrible\" is likely a <font color='blue'>negative</font> one.\n",
        "\n",
        "Here's how you <font color='blue'>count</font> bigram occurences in the `TextVectorization` layer.\n",
        "\n"
      ],
      "metadata": {
        "id": "wwbP9HBNksQI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acaRS5SfYpC4"
      },
      "source": [
        "**Configuring the `TextVectorization` layer to return token counts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csBsYZfPYpC4"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"count\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, of course, some words are bound to occur more often than others no matter what the text is about. The words <font color='blue'>\"the\", \"a,\" \"is,\"</font> and <font color='blue'>\"are\"</font> will always dominate your word count histograms, drowing out other words-despite being pretty much usless features in a classification context. How could we address this?\n",
        "\n",
        "You already guessed it: via <font color='blue'>normalization</font>. We could just normalize <font color='blue'>word counts</font> by <font color='blue'>subtracting the mean and dividing by the variance</font> (computed across the entire training dataset). That would make sense. Except most vectorized sentences consist almost <font color='blue'>entirely of zeros</font> (our previous example features 12 non-zero entries and 19,988 zero entries), a property called <font color='blue'>sparsity.</font> That's a great property to have, as it dramatically reduces compute load and reduces the risk of overfitting. If we <font color='blue'>subtracted the mean</font> from each feature, we'd <font color='blue'>wreck sparsity</font>. Thus, whatever normalization scheme we use should be divide-only. What, then, should we use as the denominator? The best practice\n",
        "is to go with something called <font color='blue'>TF-IDF</font> normalization—TF-IDF stands for <font color='blue'>term frequency, inverse document frequency.</font>\n",
        "\n",
        "TF-IDF is so common that it's built into the TextVectorization layer. All you need to do to start using it is to switch the <font color='blue'>output_mode</font> argument to <font color='blue'>tf_idf</font>."
      ],
      "metadata": {
        "id": "s6J8kjs3mfTR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Understanding TF-IDF normalization:** The more a given term <font color='blue'>appears</font> in a document, the more <font color='blue'>important</font> that term is for understanding what the document is about. At the same time, the <font color='blue'>frequency</font> at which the term appears across all documents in your dataset matters too: terms that appear in almost every document (like “the” or “a”) aren't particularly informative, while terms that appear only in a <font color='blue'>small subset</font> of all texts (like “Herzog”) are very <font color='blue'>distinctive</font>, and thus important. TF-IDF is a <font color='blue'>metric</font> that <font color='blue'>fuses</font> these two ideas. It weights a given term by taking “term frequency,” how many times the term appears in the current document, and dividing it by a measure of “document frequency,” which estimates how often the term comes up across the dataset. You'd compute it as follows:"
      ],
      "metadata": {
        "id": "qljL5E6anD0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tfidf(term, document, dataset):\n",
        "  term_freq = document.count(term)                                              # Count the frequency of a specific term\n",
        "  doc_freq = math.log(sum(doc.count(term) for doc in dataset) + 1)              # Count how often the term appears in the dataset\n",
        "  return term_freq / doc_freq"
      ],
      "metadata": {
        "id": "pPxBFpK1ZJOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXkQfE3lYpC4"
      },
      "source": [
        "**Configuring `TextVectorization` to return TF-IDF-weighted outputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61_SyUDuYpC5"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"tf_idf\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train a new model with this scheme."
      ],
      "metadata": {
        "id": "xKh5_mQ9nLn8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFV5oBcbYpC5"
      },
      "source": [
        "**Training and testing the TF-IDF bigram model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypvf7nWeYpC5",
        "outputId": "1ac1d7f4-9868-422e-b0fe-0909fc3c9497",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 8s 11ms/step - loss: 0.6008 - accuracy: 0.7249 - val_loss: 0.4585 - val_accuracy: 0.8558\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.4407 - accuracy: 0.8166 - val_loss: 0.3979 - val_accuracy: 0.8644\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.3632 - accuracy: 0.8557 - val_loss: 0.3212 - val_accuracy: 0.8576\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.3249 - accuracy: 0.8752 - val_loss: 0.3264 - val_accuracy: 0.8584\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2969 - accuracy: 0.8865 - val_loss: 0.3483 - val_accuracy: 0.8692\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2722 - accuracy: 0.8996 - val_loss: 0.3458 - val_accuracy: 0.8698\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2480 - accuracy: 0.9102 - val_loss: 0.3727 - val_accuracy: 0.8694\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2353 - accuracy: 0.9169 - val_loss: 0.3671 - val_accuracy: 0.8626\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2197 - accuracy: 0.9244 - val_loss: 0.4077 - val_accuracy: 0.8608\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2088 - accuracy: 0.9288 - val_loss: 0.4697 - val_accuracy: 0.8694\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.3343 - accuracy: 0.8512\n",
            "Test acc: 0.851\n"
          ]
        }
      ],
      "source": [
        "text_vectorization.adapt(text_only_train_ds)                                    # The adapt() call will learn the TF-IDF weights\n",
        "                                                                                # in addition to the vocabulary.\n",
        "tfidf_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "tfidf_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "tfidf_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"tfidf_2gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(tfidf_2gram_train_ds.cache(),\n",
        "          validation_data=tfidf_2gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"tfidf_2gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(tfidf_2gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gets us an <font color='blue'>85.1%</font> test accuracy on the IMDB classification task: it doesn't seem to be particularly helpful in this case. However, for many <font color='blue'>text-classification</font> datasets, it would be typical to see a <font color='blue'>one-percentage-point</font> increase when using the TF-IDF compared to plain binary encoding."
      ],
      "metadata": {
        "id": "ybEwiB_Dn2Jr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exporting a model that processes raw strings:** In the preceding examples, we did our text standardization, splitting, and indexing as part of the <font color='blue'>tf.data</font> pipeline. But if we want to export a standalone model independent of this pipeline, we should make sure that it incorporates its <font color='blue'>own text preprocessing</font> (otherwise, you'd have to <font color='blue'>reimplement</font> in the <font color='blue'>production</font> environment, which can be challenging or can lead to subtle discrepancies between the training data and the production data). Thankfully, this is straightforward.\n",
        "\n",
        "Just create a new model that reuses your *TextVectorization* layer and <font color='blue'>adds</font> to it the <font color='blue'>model</font> you just trained:\n",
        "\n"
      ],
      "metadata": {
        "id": "esKGwXsqoZW9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIHfsS8OYpC6"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(1,), dtype=\"string\")                                # A single input sample is one string\n",
        "processed_inputs = text_vectorization(inputs)                                   # Apply text preprocessing\n",
        "outputs = model(processed_inputs)                                               # Apply the previously trained model\n",
        "inference_model = keras.Model(inputs, outputs)                                  # Instantiate the end-to-end model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting model can process batches of raw strings:"
      ],
      "metadata": {
        "id": "oi5Kg5qtoxHS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBuyIY1nYpC6",
        "outputId": "0f86e02e-0322-4fc7-a17a-56be221f51df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98.35 percent positive\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "raw_text_data = tf.convert_to_tensor([\n",
        "    [\"That was an excellent movie, I loved it.\"],\n",
        "])\n",
        "predictions = inference_model(raw_text_data)\n",
        "print(f\"{float(predictions[0] * 100):.2f} percent positive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next Section-** 11.3.3 Processing words as a sequence: The sequence model approach."
      ],
      "metadata": {
        "id": "cQSnfLi8ahlh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11.4: Transformers:** See Youtube videos [here](https://www.youtube.com/watch?v=XSSTuhyAmnI) and [here](https://www.youtube.com/watch?v=4Bdc55j80l8).\n",
        "\n",
        "Transformers are built off of the 2017 paper: [Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf)."
      ],
      "metadata": {
        "id": "qu8wV8wqe3Nc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yLh7Fslqamqs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "chapter11_part01_introduction.i",
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}